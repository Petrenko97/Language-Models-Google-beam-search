{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7xILW5rkFQQ",
        "outputId": "72031d28-bbe1-4cfe-98e7-aaf8943494d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/abc.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk.corpus\n",
        "nltk.download('abc')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1aTk-U2kFQS"
      },
      "outputs": [],
      "source": [
        "sentences = nltk.corpus.abc.sents()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7dtUivAkFQT",
        "outputId": "6c277045-2d0f-4f69-ac2a-d1f0ca74d035"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "766811"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len([word for sent in sentences for word in sent])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DipXZYv1kFQU"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import regex\n",
        "import numpy as np\n",
        "\n",
        "class LM:\n",
        "    def __init__(self, n_type):\n",
        "        \"\"\"\n",
        "        type: ['bigram', 'trigram']\n",
        "        \"\"\"\n",
        "        self.n_type = n_type\n",
        "        if self.n_type not in ['bigram', 'trigram']:\n",
        "            raise Exception(\"type must be either 'bigram' or 'trigram'\")\n",
        "        \n",
        "        self.unique_voc_ = None  # Vocabulary of all the unique words of the corpus\n",
        "        self.unigram_voc_ = None  # Unigram vocabulary containing words with at least 10 counts\n",
        "        self.bigram_voc_ = None  # Bigram vocabulary\n",
        "        self.trigram_voc_ = None  # Trigram vocabulary\n",
        "\n",
        "        self.previous_words = None  # Number of bigrams where the second element is the keys of the dictionary\n",
        "        self.following_words = None  # Number of bigrams where the first element is the keys of the dictionary\n",
        "         \n",
        "    \n",
        "    @staticmethod\n",
        "    def word_cleaner(words):  # remove any character that is not a letter or number, skip the special tokens\n",
        "        \"\"\"\n",
        "        input must be a list of words\n",
        "        \"\"\"\n",
        "        allowed = ['*UNK*', '*start*', '*start1*', '*start2*', '*end*']\n",
        "        return list(filter(None, \n",
        "            [word if word in allowed else regex.sub(r\"[^a-zA-Z0-9]\", \"\", word).lower() if regex.sub(r\"[^a-zA-Z0-9]\", \"\", word) != \"\" else \"\" for word in words]))\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def bigram(words):  # create bigrams\n",
        "        return list(zip(words,words[1:]))\n",
        "    \n",
        "\n",
        "    @staticmethod\n",
        "    def trigram(words):  # create trigrams\n",
        "        return list(zip(words, words[1:], words[2:]))\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def sent_preprocessing(sentences, ngram_padding, padding=True):\n",
        "        \"\"\"\n",
        "        Cleans and pads the sentences according to the type of the model. Input must be \n",
        "        a list of lists.\n",
        "        \"\"\"\n",
        "        clean_sents = [LM.word_cleaner(sent) for sent in sentences]  # clean words\n",
        "        \n",
        "        if padding:\n",
        "            if ngram_padding == 2:  # padding for bigrams (start with *start* and end with *end*)\n",
        "                padded_sentences = [['*start*'] + sent + ['*end*'] for sent in clean_sents]\n",
        "            elif ngram_padding == 3:  # trigram padding (each sentence begins with *start1* and *start2* and ends with *end*)\n",
        "                padded_sentences = [['*start1*'] + ['*start2*'] + sent + ['*end*'] for sent in clean_sents]\n",
        "            else:\n",
        "                raise Exception('ngram_padding must be equal to 2 or 3')\n",
        "        else:\n",
        "            padded_sentences = clean_sents\n",
        "\n",
        "        return padded_sentences\n",
        "\n",
        "    \n",
        "    @staticmethod\n",
        "    def unk_replacer(words, voc):\n",
        "        \"\"\"\n",
        "        Replaces the words with a count < 10 with the special token *UNK*. Input must be a list of tokens\n",
        "        \"\"\"\n",
        "        return [word if voc[word] > 10 and (len(word) > 1 or word in ['i', 'a']) else \"*UNK*\" for word in words]\n",
        "    \n",
        "\n",
        "    def train(self, train_sentences):\n",
        "        \"\"\"\n",
        "        train_sentences must be a list of list, where each list is a different sentence.\n",
        "        \"\"\"\n",
        "        if self.n_type == 'bigram':\n",
        "            train_sents = LM.sent_preprocessing(train_sentences, 2)  # preprocess the sentences (cleans words and adds padding)\n",
        "            total_words = [word for sent in train_sents for word in sent]  # flatten list\n",
        "            \n",
        "            self.unique_voc_ = Counter(total_words)  # Dictionary with all the counts of the unique tokens\n",
        "\n",
        "            train_words = LM.unk_replacer(total_words, self.unique_voc_)  # Replace low-count tokens with *UNK*\n",
        "            self.unigram_voc_ = Counter(train_words)  # Create the unigram vocabulary\n",
        "\n",
        "            self.bigram_voc_ = Counter(LM.bigram(train_words))  # create a vocabulary of all bigrams\n",
        "            del self.bigram_voc_[('*end*', '*start*')]\n",
        "\n",
        "            self.previous_words = Counter(bi[1] for bi in list(self.bigram_voc_.keys()))  # create the voc with the number of previous words\n",
        "            self.following_words = Counter(bi[0] for bi in list(self.bigram_voc_.keys()))  # create the voc with the number of following words\n",
        "        else:\n",
        "            train_sents = LM.sent_preprocessing(train_sentences, 3)  # preprocess sentences for a trigram model\n",
        "            total_words = [word for sent in train_sents for word in sent]  # flatten list\n",
        "\n",
        "            self.unique_voc_ = Counter(total_words)\n",
        "\n",
        "            train_words = LM.unk_replacer(total_words, self.unique_voc_)\n",
        "            self.unigram_voc_ = Counter(train_words)\n",
        "            \n",
        "            self.bigram_voc_ = Counter(LM.bigram(train_words))  # creates bigram voc\n",
        "            self.trigram_voc_ = Counter(LM.trigram(train_words))  # create trigram voc\n",
        "            del self.trigram_voc_[('*end*', '*start1*', '*start2*')]\n",
        "            del self.bigram_voc_[('*end*', '*start1*')]\n",
        "\n",
        "\n",
        "    def estimate_ngram_prob(self, c_ngram, a=1):\n",
        "        \"\"\"\n",
        "        Calculates the probability of a ngram using Add-a smoothing. \n",
        "        ngram must be a bigram or a trigram in a tuple.\n",
        "        \"\"\"        \n",
        "        if a<0 and a>1:\n",
        "            raise Exception('a must be in [0,1]')\n",
        "\n",
        "        if self.n_type == 'bigram':\n",
        "            if len(c_ngram) == 2:\n",
        "                prob = (self.bigram_voc_[c_ngram] + a) / (self.unigram_voc_[c_ngram[0]] + a*np.abs(len(self.unigram_voc_)))  # add-a probability\n",
        "            else:\n",
        "                raise Exception('input is not a bigram')\n",
        "        else:\n",
        "            if len(c_ngram) == 3:  # same as above, but for trigrams\n",
        "                prob = (self.trigram_voc_[c_ngram] + a) / (self.bigram_voc_[c_ngram[:2]] + a*np.abs(len(self.unigram_voc_)))  # |V| unigram bigram or trigram?\n",
        "            else:\n",
        "                raise Exception('input is not a trigram')\n",
        "        return prob\n",
        "\n",
        "\n",
        "    def kn_prob(self, ngram):\n",
        "        \"\"\"\n",
        "        Calculate the probability of a bigram using Interpolated K-N smoothing.\n",
        "        \"\"\"\n",
        "        if len(ngram) != 2:\n",
        "            raise Exception('Interpolated K-N Smoothing is only available for bigrams')\n",
        "\n",
        "        if self.bigram_voc_[ngram] == 1:  # If the count is equal to 1, then steal 0.5\n",
        "            d = 0.5\n",
        "        else:  # else steal 0.75\n",
        "            d = 0.75\n",
        "\n",
        "        highest_term = max((self.bigram_voc_[ngram] - d), 0) / self.unigram_voc_[ngram[0]]  # first term of the interpolated kn-smoothing formula\n",
        "        \n",
        "        following_words = self.following_words[ngram[0]]  # number of words that follow the first element of the bigram\n",
        "\n",
        "        lamda = (d / self.unigram_voc_[ngram[0]]) * following_words  # interpolation weight\n",
        "\n",
        "        previous_words = self.previous_words[ngram[1]]  # number of words preceding  the second element of the bigram\n",
        "        p_cont = previous_words / len(self.bigram_voc_.keys())  # Pcontinuation\n",
        "\n",
        "        p_kn = highest_term + lamda*p_cont\n",
        "        return p_kn\n",
        "\n",
        "\n",
        "    def estimate_sent_prob(self, test_sents, padding=True, a=1, smoothing='add_a', ngram_count=False):\n",
        "        \"\"\"\n",
        "        Input must be a list of lists, where each list is a sentence. Available smoothers for bigram: 'add_a', 'kn'.\n",
        "        \"\"\"\n",
        "        if ngram_count not in [True, False]:\n",
        "            raise Exception('unk can be either se to True or False')\n",
        "\n",
        "        if a<0 and a>1:\n",
        "            raise Exception('a must be in [0,1]')\n",
        "\n",
        "        if smoothing not in ['add_a', 'kn']:\n",
        "            if self.n_type == 'trigram':\n",
        "                if smoothing == 'kn':\n",
        "                    raise Exception('K-N smoothing is only available for bigrams')\n",
        "            raise Exception('Available smoothers: [add_a, kn]')\n",
        "        \n",
        "        sent_probs = []\n",
        "        total_prob = 0\n",
        "        ngrams_count = []\n",
        "\n",
        "        if self.n_type == 'bigram':\n",
        "            if not padding:\n",
        "                test_sents = LM.sent_preprocessing(test_sents, 2, padding=False)  # do not pad sentences\n",
        "            else:\n",
        "                test_sents = LM.sent_preprocessing(test_sents, 2, padding=True)  # preprocess sentences in order to estimate their probabilities\n",
        "             \n",
        "            for sent in test_sents:\n",
        "                ngrams_count.append(len(LM.bigram(sent)))  # number of bigrams in sentence(useful for cross-entropy calculation)\n",
        "\n",
        "                for bi in LM.bigram(sent):\n",
        "                    if smoothing == 'add_a':\n",
        "                        total_prob += np.log2(self.estimate_ngram_prob(bi, a)) # on every iteration, it adds the log probability of each bigram \n",
        "                    else:\n",
        "                        total_prob += np.log2(self.kn_prob(bi))  # use kn\n",
        "\n",
        "                sent_probs.append(total_prob)  # if multiple sentences are given as an input, it creates a list with the log prob of each sentence\n",
        "                total_prob = 0  # resets total prob to 0, in order to calculate the probability of the next sentence\n",
        "        else:\n",
        "            test_sents = LM.sent_preprocessing(test_sents, 3)\n",
        "\n",
        "            for sent in test_sents:\n",
        "                ngrams_count.append(len(LM.trigram(sent)))\n",
        "\n",
        "                for tri in LM.trigram(sent):\n",
        "                    total_prob += np.log2(self.estimate_ngram_prob(tri, a))  # include P(*end*|...)\n",
        "                    \n",
        "                sent_probs.append(total_prob)  # exp to get probabilities?\n",
        "                total_prob = 0\n",
        "\n",
        "        if ngram_count is False:\n",
        "            return sent_probs\n",
        "        else:\n",
        "            return sent_probs, ngrams_count\n",
        "\n",
        "\n",
        "    def entr_perp(self, test_sents, a=1, smoothing='add_a'):\n",
        "        \"\"\"\n",
        "        Calculates the Cross-entropy and Perplexity of a list of sentences\n",
        "        \"\"\"\n",
        "        test = [LM.unk_replacer(sent, self.unique_voc_) for sent in test_sents]  # replace low-count words with *UNK*\n",
        "        probs, ngrams_count = self.estimate_sent_prob(test, smoothing=smoothing, a=a, ngram_count=True)  # get the probability of the sentence and its ngram counts\n",
        "        \n",
        "        hc = -sum(probs) / sum(ngrams_count)  # calculate cross-entropy\n",
        "        perp = 2**hc  # calculate perplexity\n",
        "\n",
        "        return hc, perp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZdYLxXFkFQW"
      },
      "source": [
        "First, we have to create an instance of the model. if n_type is equal to 'bigram', then an instance of a bigram model is created. If n_type is set to trigram, then a 'trigram' model is created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk1KhIvikFQX"
      },
      "outputs": [],
      "source": [
        "b_model = LM(n_type='bigram')\n",
        "tri_model = LM(n_type='trigram')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovqf1bPnkFQY"
      },
      "source": [
        "Next, we have to train the model. The input must be a list of lists, where each list is a sentence. All the cleaning and padding is handled by the model, so we just have to feed it with raw sentences (for example, for the bigram model, if we pass to the train method the sentence ['ThI,!s', 'iS', '.A.', 'tE==++sT'], the model will transform the sentence to ['* start *', 'this', 'is', 'a', 'test', '* end *'] and it will create all the necessary vocabularies.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r1feRxskFQY"
      },
      "source": [
        "Once the model is trained, then the following methods can be called:\n",
        "Let b_model be an instance of a bigram model:\n",
        " - b_model.unigram_voc_ -> this will return the vocabulary of all unigrams\n",
        " - b_model.bigram_voc_ -> this will return the vocabulary of all bigrams (for the trigram model we would have to make an instance of a trigram model using LM(n_type='trigram'))\n",
        " - b_model.estimate_ngram_prob() -> this will calculate the probability of a given bigram (or trigram if we use the trigram model) using Add-a smoothing, where the hyper-parameter 'a' can be tuned in order to achieve the lowest possible Cross-Entropy\n",
        " - b_model.kn_prob() -> this will calculate the probability of a given bigram using the interpolated Kneser-Ney smoothing, where the constant D is equal to 0.5 for bigrams with a count of 1 and 0.75 for the rest.\n",
        " - b_model.estimate_sent_prob() -> this will calculate the log probabilities of all the given sentences. If more than one sentence is given as an input, then it will return a list with the probabilities of each sentence (which could then be summed and thus, calculate the total log probability of ,eg, the test corpus). There are two available smoothers for bigrams. Add-a smoothing and Interpolated Kneser-Ney smoothing.\n",
        " - b_model.entr_perp() -> this will return the Cross-Entropy and Perplexity of the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mi78QdjkFQY"
      },
      "source": [
        "Some other static methods can be called (they don't require an instance creation):\n",
        " - Model.word_cleaner() -> this will clean any list of words. It will remove any character that is not a letter or number, and it will apply lower case to all the words\n",
        " - Model.sent_preprocessing() -> this will clean and pad any sentence that is given as an input\n",
        " - Model.bigram() -> this will create bigrams of a given sentence\n",
        " - Model.trigram() -> this will create trigrams of a given sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZmEgX0mkFQZ"
      },
      "outputs": [],
      "source": [
        "b_model.train(sentences)  # train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxHg_X3mkFQZ",
        "outputId": "5d3248a5-1f68-4f1e-cff3-60f10685e779"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27652"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(b_model.unique_voc_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ii4N6xKkFQZ"
      },
      "source": [
        "Estimating the probability of a bigram:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8ebSlTtkFQZ",
        "outputId": "1e2674b1-3f1c-4ef2-c5af-b7c3497a1503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add-a smoothing (with a=1) probability: 0.04117362955807776\n",
            "K-N probability: 0.12414558851175722\n"
          ]
        }
      ],
      "source": [
        "laplace = b_model.estimate_ngram_prob(('this', 'is'))\n",
        "kn = b_model.kn_prob(('this', 'is'))\n",
        "print(f\"Add-a smoothing (with a=1) probability: {laplace}\\nK-N probability: {kn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVrME5D4kFQa"
      },
      "source": [
        "Estimating the log probability of a sentence using laplace:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unZCJvOQkFQa",
        "outputId": "c2d640c8-ebba-4589-de17-25966da5f6de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-34.326750073789114]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "b_model.estimate_sent_prob([['this', 'is', 'a', 'test']], smoothing='add_a')  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_eXCijokFQa"
      },
      "source": [
        "Estimating the log probability of a sentence using kn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l675b5UukFQa",
        "outputId": "fbc2c1e9-e399-4237-88e3-863803db95b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-26.54752395643943]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "b_model.estimate_sent_prob([['this', 'is', 'a', 'test']], smoothing='kn')  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGlKDGDckFQa"
      },
      "source": [
        "Calling the unigram vocabulary attribute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HZSCHmykFQa",
        "outputId": "6f3834bb-d002-40f9-8cc0-4ad8651b8896"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'*start*': 29059,\n",
              "         'pm': 19,\n",
              "         'denies': 22,\n",
              "         'knowledge': 54,\n",
              "         'of': 19307,\n",
              "         'awb': 546,\n",
              "         'kickbacks': 26,\n",
              "         'the': 41634,\n",
              "         'prime': 109,\n",
              "         'minister': 337,\n",
              "         'has': 3492,\n",
              "         'denied': 13,\n",
              "         'he': 3999,\n",
              "         'knew': 29,\n",
              "         'was': 2018,\n",
              "         'paying': 37,\n",
              "         'to': 18671,\n",
              "         'iraq': 107,\n",
              "         'despite': 191,\n",
              "         'writing': 37,\n",
              "         'wheat': 676,\n",
              "         'exporter': 78,\n",
              "         'asking': 47,\n",
              "         'be': 4292,\n",
              "         'kept': 47,\n",
              "         'fully': 25,\n",
              "         'informed': 16,\n",
              "         'on': 4258,\n",
              "         'sales': 142,\n",
              "         '*end*': 29059,\n",
              "         'letters': 41,\n",
              "         'from': 4101,\n",
              "         'john': 216,\n",
              "         'howard': 70,\n",
              "         'and': 14895,\n",
              "         'deputy': 46,\n",
              "         'mark': 119,\n",
              "         'vaile': 68,\n",
              "         'have': 4288,\n",
              "         'been': 2163,\n",
              "         'released': 128,\n",
              "         'by': 2843,\n",
              "         'cole': 144,\n",
              "         'inquiry': 230,\n",
              "         'into': 1154,\n",
              "         'oil': 284,\n",
              "         'for': 6047,\n",
              "         'food': 435,\n",
              "         'program': 203,\n",
              "         'in': 13356,\n",
              "         'one': 1498,\n",
              "         'mr': 411,\n",
              "         'asks': 12,\n",
              "         'managing': 88,\n",
              "         'director': 216,\n",
              "         'andrew': 86,\n",
              "         'lindberg': 17,\n",
              "         'remain': 74,\n",
              "         'close': 138,\n",
              "         'contact': 49,\n",
              "         'with': 3676,\n",
              "         'government': 945,\n",
              "         'opposition': 60,\n",
              "         '*UNK*': 69009,\n",
              "         'connor': 27,\n",
              "         'says': 7482,\n",
              "         'letter': 21,\n",
              "         'sent': 67,\n",
              "         '2002': 40,\n",
              "         'same': 344,\n",
              "         'time': 878,\n",
              "         'though': 100,\n",
              "         'a': 14605,\n",
              "         'trucking': 37,\n",
              "         'company': 515,\n",
              "         'can': 1749,\n",
              "         'longer': 139,\n",
              "         'its': 1243,\n",
              "         'hands': 41,\n",
              "         'payments': 56,\n",
              "         'which': 1895,\n",
              "         'million': 868,\n",
              "         'responsibility': 26,\n",
              "         'this': 2764,\n",
              "         'must': 158,\n",
              "         'lay': 17,\n",
              "         'may': 974,\n",
              "         'at': 3490,\n",
              "         'feet': 28,\n",
              "         'coalition': 27,\n",
              "         'ministers': 15,\n",
              "         'trade': 329,\n",
              "         'agriculture': 348,\n",
              "         'said': 2196,\n",
              "         'but': 2978,\n",
              "         'show': 310,\n",
              "         'about': 1623,\n",
              "         'future': 350,\n",
              "         'do': 664,\n",
              "         'not': 2311,\n",
              "         'prove': 41,\n",
              "         'it': 5686,\n",
              "         'would': 1166,\n",
              "         'if': 1111,\n",
              "         'as': 3264,\n",
              "         'i': 1226,\n",
              "         'done': 153,\n",
              "         'anything': 111,\n",
              "         'possibly': 71,\n",
              "         'could': 1475,\n",
              "         'preserve': 18,\n",
              "         'australia': 2027,\n",
              "         'very': 812,\n",
              "         'valuable': 22,\n",
              "         'market': 544,\n",
              "         'email': 39,\n",
              "         'questions': 75,\n",
              "         'today': 535,\n",
              "         'trading': 103,\n",
              "         'manager': 133,\n",
              "         'peter': 274,\n",
              "         'questioned': 21,\n",
              "         'an': 2289,\n",
              "         'received': 101,\n",
              "         '2000': 48,\n",
              "         'that': 7634,\n",
              "         'iraqi': 38,\n",
              "         'grains': 153,\n",
              "         'board': 126,\n",
              "         'had': 1085,\n",
              "         'provide': 182,\n",
              "         'after': 810,\n",
              "         'service': 114,\n",
              "         'two': 888,\n",
              "         'colleagues': 231,\n",
              "         'did': 258,\n",
              "         'remember': 29,\n",
              "         'reading': 35,\n",
              "         'although': 192,\n",
              "         'support': 248,\n",
              "         'still': 433,\n",
              "         'plenty': 26,\n",
              "         'among': 174,\n",
              "         'grain': 427,\n",
              "         'growers': 830,\n",
              "         'central': 186,\n",
              "         'western': 452,\n",
              "         'new': 2182,\n",
              "         'south': 1103,\n",
              "         'wales': 426,\n",
              "         'producers': 241,\n",
              "         'say': 1222,\n",
              "         'they': 3426,\n",
              "         'attempts': 29,\n",
              "         'get': 649,\n",
              "         'best': 203,\n",
              "         'prices': 605,\n",
              "         'their': 2084,\n",
              "         'products': 136,\n",
              "         'think': 606,\n",
              "         'all': 926,\n",
              "         'overseas': 80,\n",
              "         'interests': 39,\n",
              "         'try': 154,\n",
              "         'single': 245,\n",
              "         'desk': 150,\n",
              "         'put': 292,\n",
              "         'aside': 13,\n",
              "         'stories': 16,\n",
              "         'are': 4796,\n",
              "         'going': 527,\n",
              "         'round': 54,\n",
              "         'commission': 93,\n",
              "         'everything': 58,\n",
              "         'way': 578,\n",
              "         'people': 1281,\n",
              "         'got': 338,\n",
              "         'things': 222,\n",
              "         'business': 170,\n",
              "         'middle': 98,\n",
              "         'east': 244,\n",
              "         'asian': 29,\n",
              "         'countries': 160,\n",
              "         'producer': 69,\n",
              "         'actually': 232,\n",
              "         'pretty': 94,\n",
              "         'reasonable': 25,\n",
              "         'system': 634,\n",
              "         'give': 198,\n",
              "         'them': 867,\n",
              "         'fair': 50,\n",
              "         'moment': 121,\n",
              "         'average': 184,\n",
              "         've': 539,\n",
              "         'performed': 21,\n",
              "         'fairly': 57,\n",
              "         'well': 469,\n",
              "         'another': 394,\n",
              "         'biggest': 196,\n",
              "         'thing': 162,\n",
              "         'someone': 89,\n",
              "         'else': 46,\n",
              "         'taking': 121,\n",
              "         'over': 973,\n",
              "         'is': 8046,\n",
              "         'whether': 356,\n",
              "         'will': 2822,\n",
              "         'too': 269,\n",
              "         'much': 504,\n",
              "         'there': 2049,\n",
              "         'take': 357,\n",
              "         'advantage': 59,\n",
              "         'analyst': 78,\n",
              "         'predicts': 33,\n",
              "         'drop': 125,\n",
              "         '20': 291,\n",
              "         'tonne': 86,\n",
              "         'back': 468,\n",
              "         'malcolm': 29,\n",
              "         'pool': 98,\n",
              "         'returns': 51,\n",
              "         'already': 279,\n",
              "         'dropped': 43,\n",
              "         'year': 1222,\n",
              "         'price': 380,\n",
              "         'past': 277,\n",
              "         'five': 261,\n",
              "         'years': 1230,\n",
              "         'through': 489,\n",
              "         'export': 287,\n",
              "         'monopoly': 34,\n",
              "         'severely': 13,\n",
              "         'eroded': 11,\n",
              "         'sa': 51,\n",
              "         'farmers': 1153,\n",
              "         'help': 541,\n",
              "         'fire': 139,\n",
              "         'neighbours': 15,\n",
              "         'hay': 57,\n",
              "         'across': 344,\n",
              "         'border': 29,\n",
              "         'wake': 60,\n",
              "         'bushfires': 40,\n",
              "         'just': 748,\n",
              "         'few': 234,\n",
              "         'days': 200,\n",
              "         'donated': 20,\n",
              "         '250': 26,\n",
              "         'tonnes': 224,\n",
              "         'cattle': 403,\n",
              "         'beginning': 37,\n",
              "         'fodder': 21,\n",
              "         'drive': 51,\n",
              "         'coordinator': 11,\n",
              "         'response': 139,\n",
              "         'week': 446,\n",
              "         'gone': 73,\n",
              "         'places': 82,\n",
              "         'load': 24,\n",
              "         'or': 1973,\n",
              "         'up': 1591,\n",
              "         'loads': 19,\n",
              "         'we': 3107,\n",
              "         'man': 88,\n",
              "         'full': 120,\n",
              "         'rest': 56,\n",
              "         'straight': 26,\n",
              "         're': 729,\n",
              "         'moving': 82,\n",
              "         'highway': 15,\n",
              "         'major': 340,\n",
              "         'between': 579,\n",
              "         'northern': 330,\n",
              "         'territory': 184,\n",
              "         'remains': 126,\n",
              "         'victoria': 264,\n",
              "         'river': 249,\n",
              "         'cut': 201,\n",
              "         'also': 1331,\n",
              "         'flooded': 12,\n",
              "         'remote': 124,\n",
              "         'hole': 50,\n",
              "         'aboriginal': 80,\n",
              "         'community': 189,\n",
              "         'simon': 21,\n",
              "         'describes': 44,\n",
              "         'hundred': 62,\n",
              "         'higher': 251,\n",
              "         'ground': 138,\n",
              "         'vehicles': 32,\n",
              "         'moved': 42,\n",
              "         'out': 1241,\n",
              "         'set': 307,\n",
              "         'were': 1326,\n",
              "         'more': 2191,\n",
              "         'couple': 70,\n",
              "         'boats': 28,\n",
              "         'onto': 95,\n",
              "         'only': 692,\n",
              "         '500': 115,\n",
              "         'metres': 100,\n",
              "         'might': 335,\n",
              "         'little': 244,\n",
              "         'start': 171,\n",
              "         'down': 490,\n",
              "         'sold': 102,\n",
              "         'tasmania': 174,\n",
              "         'main': 117,\n",
              "         'changed': 47,\n",
              "         'second': 143,\n",
              "         'three': 475,\n",
              "         'former': 133,\n",
              "         'state': 515,\n",
              "         'owned': 41,\n",
              "         'tasmanian': 107,\n",
              "         'local': 232,\n",
              "         'agribusiness': 23,\n",
              "         'roberts': 20,\n",
              "         'limited': 83,\n",
              "         'deal': 190,\n",
              "         'includes': 68,\n",
              "         'silos': 16,\n",
              "         'bid': 56,\n",
              "         'when': 1030,\n",
              "         'first': 812,\n",
              "         'disappointed': 30,\n",
              "         'weren': 25,\n",
              "         'successful': 47,\n",
              "         'point': 145,\n",
              "         'wine': 229,\n",
              "         'workers': 181,\n",
              "         'stop': 134,\n",
              "         'work': 549,\n",
              "         'wines': 31,\n",
              "         'stanley': 17,\n",
              "         'walked': 21,\n",
              "         'off': 470,\n",
              "         'job': 87,\n",
              "         'staff': 75,\n",
              "         'morning': 68,\n",
              "         'dispute': 32,\n",
              "         'bargaining': 11,\n",
              "         'agreement': 103,\n",
              "         'comes': 130,\n",
              "         'region': 247,\n",
              "         'grape': 102,\n",
              "         'crush': 12,\n",
              "         'gets': 58,\n",
              "         'under': 470,\n",
              "         'took': 126,\n",
              "         'matter': 121,\n",
              "         'industrial': 54,\n",
              "         'relations': 27,\n",
              "         'friday': 30,\n",
              "         'wool': 414,\n",
              "         'body': 299,\n",
              "         'eyes': 52,\n",
              "         'industry': 943,\n",
              "         '50': 190,\n",
              "         'billion': 186,\n",
              "         'global': 226,\n",
              "         'target': 52,\n",
              "         'promotion': 12,\n",
              "         'australian': 1384,\n",
              "         'innovation': 66,\n",
              "         'awi': 64,\n",
              "         'showing': 70,\n",
              "         'blend': 15,\n",
              "         'wear': 19,\n",
              "         'manufacturers': 22,\n",
              "         'largest': 144,\n",
              "         'being': 806,\n",
              "         'held': 86,\n",
              "         'germany': 40,\n",
              "         'stephens': 11,\n",
              "         'end': 246,\n",
              "         'shoppers': 16,\n",
              "         'willing': 22,\n",
              "         'pay': 165,\n",
              "         'sports': 26,\n",
              "         'sector': 179,\n",
              "         'certainly': 165,\n",
              "         'growing': 210,\n",
              "         'world': 613,\n",
              "         'no': 666,\n",
              "         'secret': 33,\n",
              "         'hasn': 44,\n",
              "         'big': 356,\n",
              "         'share': 96,\n",
              "         'level': 182,\n",
              "         'particularly': 153,\n",
              "         'merino': 31,\n",
              "         'really': 360,\n",
              "         'almost': 197,\n",
              "         'below': 85,\n",
              "         'radar': 23,\n",
              "         'organisation': 90,\n",
              "         'step': 97,\n",
              "         'campaign': 94,\n",
              "         'rodeo': 32,\n",
              "         'attack': 38,\n",
              "         'animal': 274,\n",
              "         'rights': 59,\n",
              "         'activists': 14,\n",
              "         'destroyed': 47,\n",
              "         'weekend': 92,\n",
              "         'event': 117,\n",
              "         'horse': 63,\n",
              "         'breaking': 24,\n",
              "         'leg': 24,\n",
              "         'saturday': 12,\n",
              "         'weeks': 166,\n",
              "         'ago': 349,\n",
              "         'bull': 43,\n",
              "         'apparently': 20,\n",
              "         'during': 346,\n",
              "         'riding': 11,\n",
              "         'competition': 130,\n",
              "         'owner': 40,\n",
              "         'both': 268,\n",
              "         'animals': 301,\n",
              "         'brian': 44,\n",
              "         'fish': 193,\n",
              "         'welfare': 52,\n",
              "         'issue': 316,\n",
              "         'against': 223,\n",
              "         'cruelty': 13,\n",
              "         'her': 255,\n",
              "         'efforts': 54,\n",
              "         'banned': 43,\n",
              "         'snails': 26,\n",
              "         'used': 698,\n",
              "         'cancer': 217,\n",
              "         'research': 1145,\n",
              "         'investigate': 58,\n",
              "         'sea': 183,\n",
              "         'eventually': 75,\n",
              "         'treat': 49,\n",
              "         'until': 232,\n",
              "         'now': 861,\n",
              "         'snail': 15,\n",
              "         'population': 126,\n",
              "         'virtually': 30,\n",
              "         'flinders': 22,\n",
              "         'university': 966,\n",
              "         'hopes': 122,\n",
              "         'discover': 13,\n",
              "         'beneficial': 19,\n",
              "         'compounds': 40,\n",
              "         'known': 311,\n",
              "         'marine': 107,\n",
              "         'biologist': 23,\n",
              "         'dr': 764,\n",
              "         'follows': 16,\n",
              "         'where': 510,\n",
              "         'clinical': 79,\n",
              "         'trials': 79,\n",
              "         'investigating': 31,\n",
              "         'anti': 47,\n",
              "         'properties': 126,\n",
              "         'looking': 316,\n",
              "         'currently': 143,\n",
              "         'harvested': 23,\n",
              "         'considered': 88,\n",
              "         'useful': 51,\n",
              "         'resource': 75,\n",
              "         'so': 1138,\n",
              "         'lot': 328,\n",
              "         'potential': 162,\n",
              "         'economic': 77,\n",
              "         'benefits': 105,\n",
              "         'side': 116,\n",
              "         'she': 754,\n",
              "         'processors': 63,\n",
              "         'fail': 28,\n",
              "         'meet': 101,\n",
              "         'kangaroo': 19,\n",
              "         'meat': 218,\n",
              "         'demand': 190,\n",
              "         'international': 336,\n",
              "         'putting': 64,\n",
              "         'pressure': 171,\n",
              "         'high': 489,\n",
              "         'harvesting': 38,\n",
              "         'met': 54,\n",
              "         'leaving': 44,\n",
              "         'gap': 22,\n",
              "         'phil': 17,\n",
              "         'king': 54,\n",
              "         'perth': 46,\n",
              "         'attracted': 23,\n",
              "         'low': 300,\n",
              "         'fat': 45,\n",
              "         'content': 53,\n",
              "         'consuming': 14,\n",
              "         'large': 270,\n",
              "         'amounts': 53,\n",
              "         'far': 337,\n",
              "         'know': 304,\n",
              "         'every': 165,\n",
              "         'produced': 126,\n",
              "         'human': 435,\n",
              "         'consumption': 48,\n",
              "         'goes': 83,\n",
              "         'russian': 24,\n",
              "         'warned': 37,\n",
              "         'snake': 17,\n",
              "         'alert': 18,\n",
              "         'temperatures': 134,\n",
              "         'soaring': 11,\n",
              "         'summer': 80,\n",
              "         'southern': 230,\n",
              "         'snakes': 22,\n",
              "         'move': 176,\n",
              "         'keep': 193,\n",
              "         'open': 146,\n",
              "         'paddock': 24,\n",
              "         'especially': 93,\n",
              "         'areas': 341,\n",
              "         'hit': 163,\n",
              "         'forced': 82,\n",
              "         'usual': 21,\n",
              "         'habitat': 35,\n",
              "         'rescue': 20,\n",
              "         'these': 717,\n",
              "         'words': 63,\n",
              "         'advice': 40,\n",
              "         'any': 552,\n",
              "         'who': 1061,\n",
              "         'regularly': 25,\n",
              "         'bush': 55,\n",
              "         'walking': 23,\n",
              "         'land': 265,\n",
              "         'working': 239,\n",
              "         'always': 116,\n",
              "         'carry': 71,\n",
              "         'least': 193,\n",
              "         'mobile': 75,\n",
              "         'phone': 70,\n",
              "         'aerial': 18,\n",
              "         'spraying': 20,\n",
              "         'begins': 22,\n",
              "         'control': 194,\n",
              "         'locust': 17,\n",
              "         'threat': 81,\n",
              "         'country': 300,\n",
              "         'begun': 39,\n",
              "         'locusts': 27,\n",
              "         'made': 447,\n",
              "         'continued': 27,\n",
              "         'rain': 239,\n",
              "         'warm': 53,\n",
              "         'weather': 178,\n",
              "         'assisting': 13,\n",
              "         'breeding': 65,\n",
              "         'conditions': 291,\n",
              "         'pastures': 13,\n",
              "         'crops': 289,\n",
              "         'wiped': 32,\n",
              "         'pest': 44,\n",
              "         'injury': 19,\n",
              "         'won': 111,\n",
              "         'queensland': 542,\n",
              "         'farmer': 160,\n",
              "         'him': 69,\n",
              "         'running': 73,\n",
              "         'queen': 18,\n",
              "         'lead': 205,\n",
              "         'commonwealth': 27,\n",
              "         'games': 66,\n",
              "         'bill': 114,\n",
              "         'travelled': 20,\n",
              "         'harbour': 13,\n",
              "         'run': 144,\n",
              "         'his': 712,\n",
              "         'prevent': 79,\n",
              "         'making': 231,\n",
              "         'metre': 52,\n",
              "         'my': 123,\n",
              "         'haven': 70,\n",
              "         'able': 306,\n",
              "         'than': 1481,\n",
              "         'walk': 43,\n",
              "         'since': 306,\n",
              "         'promise': 27,\n",
              "         'you': 1193,\n",
              "         'because': 916,\n",
              "         'such': 588,\n",
              "         'rush': 11,\n",
              "         'nz': 18,\n",
              "         'apple': 64,\n",
              "         'debate': 98,\n",
              "         'continues': 56,\n",
              "         'zealand': 178,\n",
              "         'newspaper': 11,\n",
              "         'members': 111,\n",
              "         'concern': 95,\n",
              "         'regarding': 16,\n",
              "         'science': 338,\n",
              "         'draft': 53,\n",
              "         'import': 67,\n",
              "         'risk': 308,\n",
              "         'analysis': 110,\n",
              "         'last': 656,\n",
              "         'month': 239,\n",
              "         'biosecurity': 52,\n",
              "         'other': 1134,\n",
              "         'pests': 15,\n",
              "         'diseases': 89,\n",
              "         'apples': 37,\n",
              "         'imported': 46,\n",
              "         'rules': 67,\n",
              "         'scientific': 119,\n",
              "         'evidence': 336,\n",
              "         'substantial': 27,\n",
              "         'disease': 364,\n",
              "         'according': 287,\n",
              "         'professional': 25,\n",
              "         'shows': 247,\n",
              "         'mature': 25,\n",
              "         'pose': 17,\n",
              "         'however': 99,\n",
              "         'spokesperson': 39,\n",
              "         'based': 330,\n",
              "         'access': 166,\n",
              "         'group': 467,\n",
              "         'provided': 49,\n",
              "         'mathematical': 26,\n",
              "         'model': 88,\n",
              "         'determine': 71,\n",
              "         'assessment': 35,\n",
              "         'report': 530,\n",
              "         'published': 230,\n",
              "         'december': 42,\n",
              "         'anyone': 42,\n",
              "         'read': 48,\n",
              "         'reproduce': 15,\n",
              "         'given': 209,\n",
              "         'chairman': 148,\n",
              "         'task': 45,\n",
              "         'force': 111,\n",
              "         'surprising': 41,\n",
              "         'exercise': 36,\n",
              "         'right': 266,\n",
              "         'presented': 76,\n",
              "         'younger': 32,\n",
              "         'trees': 112,\n",
              "         'producing': 77,\n",
              "         'trial': 87,\n",
              "         'young': 215,\n",
              "         'williams': 28,\n",
              "         'pear': 15,\n",
              "         'fruit': 345,\n",
              "         'planted': 16,\n",
              "         'usually': 84,\n",
              "         'don': 405,\n",
              "         'produce': 243,\n",
              "         'six': 205,\n",
              "         'old': 226,\n",
              "         'part': 334,\n",
              "         'experimental': 29,\n",
              "         'project': 238,\n",
              "         'funded': 56,\n",
              "         'fruits': 27,\n",
              "         'association': 325,\n",
              "         'horticulture': 58,\n",
              "         'family': 136,\n",
              "         'located': 34,\n",
              "         'consultant': 44,\n",
              "         'van': 29,\n",
              "         'aim': 20,\n",
              "         'increase': 287,\n",
              "         'number': 365,\n",
              "         'grown': 78,\n",
              "         'encouraging': 27,\n",
              "         'earlier': 171,\n",
              "         'federal': 599,\n",
              "         'national': 660,\n",
              "         'mp': 19,\n",
              "         'supports': 43,\n",
              "         'member': 98,\n",
              "         'parkes': 13,\n",
              "         'brought': 63,\n",
              "         'role': 106,\n",
              "         'top': 166,\n",
              "         'party': 76,\n",
              "         'itself': 102,\n",
              "         'become': 187,\n",
              "         'pro': 11,\n",
              "         'active': 53,\n",
              "         'make': 628,\n",
              "         'themselves': 120,\n",
              "         'different': 386,\n",
              "         'represent': 20,\n",
              "         'regional': 142,\n",
              "         'better': 354,\n",
              "         'then': 497,\n",
              "         'liberal': 27,\n",
              "         'deaths': 52,\n",
              "         'believed': 95,\n",
              "         'due': 265,\n",
              "         'lack': 129,\n",
              "         'oxygen': 64,\n",
              "         'department': 214,\n",
              "         'primary': 106,\n",
              "         'industries': 143,\n",
              "         'kill': 45,\n",
              "         'lake': 42,\n",
              "         '150': 56,\n",
              "         '200': 108,\n",
              "         'native': 102,\n",
              "         'died': 84,\n",
              "         'incident': 21,\n",
              "         'district': 48,\n",
              "         'fisheries': 41,\n",
              "         'officer': 56,\n",
              "         'phillip': 17,\n",
              "         'murray': 200,\n",
              "         'golden': 21,\n",
              "         'silver': 19,\n",
              "         'killed': 67,\n",
              "         'introduced': 62,\n",
              "         'species': 331,\n",
              "         'suggest': 135,\n",
              "         'result': 171,\n",
              "         'increased': 181,\n",
              "         'water': 1263,\n",
              "         'flow': 82,\n",
              "         'chemical': 127,\n",
              "         'vegetable': 71,\n",
              "         'labels': 19,\n",
              "         'ausveg': 21,\n",
              "         'labelling': 34,\n",
              "         'laws': 105,\n",
              "         'nobody': 16,\n",
              "         'non': 104,\n",
              "         'consumers': 86,\n",
              "         'thinking': 45,\n",
              "         'buying': 63,\n",
              "         'false': 18,\n",
              "         'poor': 86,\n",
              "         'red': 126,\n",
              "         'west': 258,\n",
              "         'kimberley': 38,\n",
              "         'wa': 157,\n",
              "         'soil': 69,\n",
              "         'available': 150,\n",
              "         'facing': 70,\n",
              "         'expand': 19,\n",
              "         'sweet': 14,\n",
              "         'potato': 28,\n",
              "         'grower': 118,\n",
              "         'paul': 61,\n",
              "         'relies': 11,\n",
              "         'broome': 16,\n",
              "         'ones': 88,\n",
              "         'connected': 25,\n",
              "         'grid': 19,\n",
              "         'applying': 25,\n",
              "         'nine': 64,\n",
              "         'kilometre': 42,\n",
              "         'extension': 25,\n",
              "         'current': 259,\n",
              "         'bring': 68,\n",
              "         'line': 136,\n",
              "         'power': 230,\n",
              "         'possible': 188,\n",
              "         'customers': 44,\n",
              "         'connection': 27,\n",
              "         'costs': 180,\n",
              "         'regardless': 18,\n",
              "         'distance': 39,\n",
              "         'existing': 81,\n",
              "         'causing': 90,\n",
              "         'headaches': 16,\n",
              "         'june': 62,\n",
              "         'title': 40,\n",
              "         'improve': 130,\n",
              "         'cleared': 26,\n",
              "         'issues': 129,\n",
              "         'resolved': 15,\n",
              "         'area': 247,\n",
              "         'surveyed': 22,\n",
              "         'bed': 22,\n",
              "         'paid': 85,\n",
              "         'clear': 122,\n",
              "         'apply': 49,\n",
              "         'planning': 74,\n",
              "         'infrastructure': 83,\n",
              "         'seven': 99,\n",
              "         'delay': 35,\n",
              "         'should': 483,\n",
              "         'aware': 45,\n",
              "         'hold': 74,\n",
              "         'office': 48,\n",
              "         'ms': 34,\n",
              "         'worked': 68,\n",
              "         'favour': 28,\n",
              "         '2004': 91,\n",
              "         'property': 81,\n",
              "         'official': 33,\n",
              "         'before': 461,\n",
              "         'potatoes': 17,\n",
              "         'stay': 59,\n",
              "         'fishers': 14,\n",
              "         'decided': 50,\n",
              "         'closing': 13,\n",
              "         'commercial': 108,\n",
              "         '300': 81,\n",
              "         'dead': 39,\n",
              "         'eels': 12,\n",
              "         'discovered': 173,\n",
              "         'near': 239,\n",
              "         'levels': 296,\n",
              "         'acting': 21,\n",
              "         'management': 134,\n",
              "         'further': 211,\n",
              "         'samples': 80,\n",
              "         'tomorrow': 39,\n",
              "         'rural': 384,\n",
              "         'woman': 62,\n",
              "         'next': 476,\n",
              "         '10': 408,\n",
              "         'seem': 69,\n",
              "         'like': 997,\n",
              "         'find': 306,\n",
              "         'macadamia': 12,\n",
              "         'win': 55,\n",
              "         'guide': 12,\n",
              "         'promoting': 13,\n",
              "         'sustainability': 16,\n",
              "         'admits': 26,\n",
              "         'even': 435,\n",
              "         'carrying': 32,\n",
              "         'burning': 38,\n",
              "         'yesterday': 129,\n",
              "         'heard': 60,\n",
              "         'officers': 24,\n",
              "         'feel': 77,\n",
              "         'intensity': 14,\n",
              "         'fires': 69,\n",
              "         'fuel': 252,\n",
              "         'reduction': 37,\n",
              "         'burns': 13,\n",
              "         'carried': 73,\n",
              "         'park': 37,\n",
              "         'vff': 21,\n",
              "         'branch': 31,\n",
              "         'secretary': 46,\n",
              "         'felt': 25,\n",
              "         'enough': 260,\n",
              "         'contributed': 24,\n",
              "         'destructive': 11,\n",
              "         'geoff': 19,\n",
              "         'evans': 12,\n",
              "         'agency': 91,\n",
              "         'policy': 94,\n",
              "         'some': 1251,\n",
              "         'keen': 24,\n",
              "         'does': 268,\n",
              "         'allow': 147,\n",
              "         'controlled': 41,\n",
              "         'times': 249,\n",
              "         'giving': 51,\n",
              "         'small': 343,\n",
              "         'window': 20,\n",
              "         'opportunity': 70,\n",
              "         'strong': 159,\n",
              "         'division': 27,\n",
              "         'within': 234,\n",
              "         'less': 330,\n",
              "         '000': 699,\n",
              "         'hectares': 58,\n",
              "         'burnt': 19,\n",
              "         'ag': 15,\n",
              "         'agencies': 33,\n",
              "         'aid': 43,\n",
              "         'announced': 115,\n",
              "         'millions': 80,\n",
              "         'dollars': 99,\n",
              "         'recovery': 43,\n",
              "         'effort': 46,\n",
              "         'including': 332,\n",
              "         'blaze': 12,\n",
              "         'ministerial': 11,\n",
              "         'assessing': 14,\n",
              "         'need': 481,\n",
              "         'supplies': 71,\n",
              "         'victorian': 149,\n",
              "         'federation': 126,\n",
              "         'contractors': 21,\n",
              "         'affected': 136,\n",
              "         'hundreds': 93,\n",
              "         '21': 34,\n",
              "         'semi': 12,\n",
              "         'collection': 26,\n",
              "         'surviving': 13,\n",
              "         'bruce': 28,\n",
              "         'farms': 123,\n",
              "         'helping': 63,\n",
              "         'sheep': 305,\n",
              "         'fixing': 11,\n",
              "         'tim': 26,\n",
              "         'came': 115,\n",
              "         'around': 665,\n",
              "         'donate': 12,\n",
              "         'scott': 33,\n",
              "         'wilson': 17,\n",
              "         'went': 87,\n",
              "         'collect': 26,\n",
              "         'neil': 23,\n",
              "         'james': 67,\n",
              "         'amazing': 13,\n",
              "         'blamed': 47,\n",
              "         'fresh': 65,\n",
              "         '12': 182,\n",
              "         'per': 722,\n",
              "         'cent': 577,\n",
              "         'jump': 32,\n",
              "         'cost': 229,\n",
              "         'latest': 189,\n",
              "         'rabobank': 14,\n",
              "         'milk': 88,\n",
              "         'vegetables': 47,\n",
              "         'ben': 21,\n",
              "         'russell': 21,\n",
              "         'money': 195,\n",
              "         'case': 217,\n",
              "         'passing': 21,\n",
              "         'contrary': 13,\n",
              "         'see': 440,\n",
              "         'retail': 20,\n",
              "         'falling': 78,\n",
              "         'slow': 66,\n",
              "         'exports': 223,\n",
              "         'traditional': 80,\n",
              "         'markets': 151,\n",
              "         'egypt': 23,\n",
              "         'china': 151,\n",
              "         'india': 74,\n",
              "         'failed': 61,\n",
              "         'deliver': 48,\n",
              "         'expected': 288,\n",
              "         'contracts': 75,\n",
              "         'crop': 269,\n",
              "         'record': 230,\n",
              "         'tenders': 14,\n",
              "         'trader': 13,\n",
              "         'lloyd': 12,\n",
              "         'george': 33,\n",
              "         'range': 154,\n",
              "         'factors': 67,\n",
              "         'important': 246,\n",
              "         'customer': 19,\n",
              "         'period': 128,\n",
              "         'significant': 151,\n",
              "         'recent': 192,\n",
              "         'months': 305,\n",
              "         'exporting': 27,\n",
              "         'quantities': 11,\n",
              "         'whole': 138,\n",
              "         'broader': 13,\n",
              "         'hope': 113,\n",
              "         'sell': 112,\n",
              "         'quantity': 14,\n",
              "         'harvest': 161,\n",
              "         'david': 143,\n",
              "         'johnson': 32,\n",
              "         'having': 183,\n",
              "         'impact': 270,\n",
              "         'lost': 123,\n",
              "         'submitted': 18,\n",
              "         'tender': 33,\n",
              "         'supply': 159,\n",
              "         'll': 195,\n",
              "         'absolutely': 30,\n",
              "         'probably': 321,\n",
              "         'relatively': 88,\n",
              "         'compared': 134,\n",
              "         'structure': 80,\n",
              "         'previous': 119,\n",
              "         'return': 60,\n",
              "         'look': 315,\n",
              "         'fact': 136,\n",
              "         'extremely': 65,\n",
              "         'comments': 22,\n",
              "         'season': 287,\n",
              "         'estimates': 68,\n",
              "         'lifting': 16,\n",
              "         'hard': 151,\n",
              "         '00': 13,\n",
              "         'mixed': 54,\n",
              "         'outlook': 55,\n",
              "         'us': 1096,\n",
              "         'brazil': 33,\n",
              "         'mean': 141,\n",
              "         'canola': 92,\n",
              "         'alternative': 74,\n",
              "         'seed': 72,\n",
              "         'barley': 57,\n",
              "         ...})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "b_model.unigram_voc_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbFyq0SqkFQb"
      },
      "source": [
        "Calling the bigram vocabulary output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aat7NCMZkFQb",
        "outputId": "f81af4ca-4a21-4659-f3c9-68371e6d2d4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({('*start*', 'pm'): 9,\n",
              "         ('pm', 'denies'): 1,\n",
              "         ('denies', 'knowledge'): 1,\n",
              "         ('knowledge', 'of'): 18,\n",
              "         ('of', 'awb'): 36,\n",
              "         ('awb', 'kickbacks'): 5,\n",
              "         ('kickbacks', 'the'): 1,\n",
              "         ('the', 'prime'): 40,\n",
              "         ('prime', 'minister'): 91,\n",
              "         ('minister', 'has'): 5,\n",
              "         ('has', 'denied'): 7,\n",
              "         ('denied', 'he'): 2,\n",
              "         ('he', 'knew'): 4,\n",
              "         ('knew', 'awb'): 2,\n",
              "         ('awb', 'was'): 9,\n",
              "         ('was', 'paying'): 3,\n",
              "         ('paying', 'kickbacks'): 2,\n",
              "         ('kickbacks', 'to'): 12,\n",
              "         ('to', 'iraq'): 32,\n",
              "         ('iraq', 'despite'): 1,\n",
              "         ('despite', 'writing'): 1,\n",
              "         ('writing', 'to'): 2,\n",
              "         ('to', 'the'): 1469,\n",
              "         ('the', 'wheat'): 75,\n",
              "         ('wheat', 'exporter'): 49,\n",
              "         ('exporter', 'asking'): 1,\n",
              "         ('asking', 'to'): 1,\n",
              "         ('to', 'be'): 1215,\n",
              "         ('be', 'kept'): 7,\n",
              "         ('kept', 'fully'): 1,\n",
              "         ('fully', 'informed'): 1,\n",
              "         ('informed', 'on'): 1,\n",
              "         ('on', 'iraq'): 4,\n",
              "         ('iraq', 'wheat'): 11,\n",
              "         ('wheat', 'sales'): 8,\n",
              "         ('sales', '*end*'): 15,\n",
              "         ('*start*', 'letters'): 1,\n",
              "         ('letters', 'from'): 1,\n",
              "         ('from', 'john'): 2,\n",
              "         ('john', 'howard'): 35,\n",
              "         ('howard', 'and'): 3,\n",
              "         ('and', 'deputy'): 3,\n",
              "         ('deputy', 'prime'): 22,\n",
              "         ('minister', 'mark'): 24,\n",
              "         ('mark', 'vaile'): 37,\n",
              "         ('vaile', 'to'): 2,\n",
              "         ('to', 'awb'): 9,\n",
              "         ('awb', 'have'): 3,\n",
              "         ('have', 'been'): 747,\n",
              "         ('been', 'released'): 9,\n",
              "         ('released', 'by'): 12,\n",
              "         ('by', 'the'): 607,\n",
              "         ('the', 'cole'): 85,\n",
              "         ('cole', 'inquiry'): 88,\n",
              "         ('inquiry', 'into'): 31,\n",
              "         ('into', 'the'): 372,\n",
              "         ('the', 'oil'): 84,\n",
              "         ('oil', 'for'): 77,\n",
              "         ('for', 'food'): 98,\n",
              "         ('food', 'program'): 17,\n",
              "         ('program', '*end*'): 34,\n",
              "         ('*start*', 'in'): 579,\n",
              "         ('in', 'one'): 56,\n",
              "         ('one', 'of'): 452,\n",
              "         ('of', 'the'): 4666,\n",
              "         ('the', 'letters'): 3,\n",
              "         ('letters', 'mr'): 1,\n",
              "         ('mr', 'howard'): 19,\n",
              "         ('howard', 'asks'): 1,\n",
              "         ('asks', 'awb'): 1,\n",
              "         ('awb', 'managing'): 3,\n",
              "         ('managing', 'director'): 63,\n",
              "         ('director', 'andrew'): 9,\n",
              "         ('andrew', 'lindberg'): 12,\n",
              "         ('lindberg', 'to'): 1,\n",
              "         ('to', 'remain'): 12,\n",
              "         ('remain', 'in'): 8,\n",
              "         ('in', 'close'): 3,\n",
              "         ('close', 'contact'): 4,\n",
              "         ('contact', 'with'): 24,\n",
              "         ('with', 'the'): 740,\n",
              "         ('the', 'government'): 236,\n",
              "         ('government', 'on'): 6,\n",
              "         ('*start*', 'the'): 4603,\n",
              "         ('the', 'opposition'): 15,\n",
              "         ('opposition', '*UNK*'): 7,\n",
              "         ('*UNK*', '*UNK*'): 8488,\n",
              "         ('*UNK*', 'connor'): 27,\n",
              "         ('connor', 'says'): 10,\n",
              "         ('says', 'the'): 1301,\n",
              "         ('the', 'letter'): 3,\n",
              "         ('letter', 'was'): 1,\n",
              "         ('was', 'sent'): 4,\n",
              "         ('sent', 'in'): 2,\n",
              "         ('in', '2002'): 19,\n",
              "         ('2002', 'the'): 4,\n",
              "         ('the', 'same'): 338,\n",
              "         ('same', 'time'): 37,\n",
              "         ('time', 'awb'): 1,\n",
              "         ('iraq', 'though'): 1,\n",
              "         ('though', 'a'): 4,\n",
              "         ('a', '*UNK*'): 2148,\n",
              "         ('*UNK*', 'trucking'): 4,\n",
              "         ('trucking', 'company'): 6,\n",
              "         ('company', '*end*'): 28,\n",
              "         ('*start*', 'he'): 697,\n",
              "         ('he', 'says'): 1358,\n",
              "         ('government', 'can'): 7,\n",
              "         ('can', 'longer'): 1,\n",
              "         ('longer', '*UNK*'): 19,\n",
              "         ('*UNK*', 'its'): 109,\n",
              "         ('its', 'hands'): 1,\n",
              "         ('hands', 'of'): 5,\n",
              "         ('the', '*UNK*'): 5191,\n",
              "         ('*UNK*', 'payments'): 11,\n",
              "         ('payments', 'which'): 1,\n",
              "         ('which', '*UNK*'): 136,\n",
              "         ('*UNK*', 'million'): 363,\n",
              "         ('million', '*end*'): 53,\n",
              "         ('the', 'responsibility'): 3,\n",
              "         ('responsibility', 'for'): 13,\n",
              "         ('for', 'this'): 55,\n",
              "         ('this', 'must'): 1,\n",
              "         ('must', 'lay'): 1,\n",
              "         ('lay', 'may'): 1,\n",
              "         ('may', '*UNK*'): 39,\n",
              "         ('*UNK*', 'at'): 439,\n",
              "         ('at', 'the'): 1248,\n",
              "         ('the', 'feet'): 4,\n",
              "         ('feet', 'of'): 1,\n",
              "         ('of', 'coalition'): 2,\n",
              "         ('coalition', 'ministers'): 1,\n",
              "         ('ministers', 'in'): 1,\n",
              "         ('in', 'trade'): 4,\n",
              "         ('trade', 'agriculture'): 1,\n",
              "         ('agriculture', 'and'): 47,\n",
              "         ('and', 'the'): 972,\n",
              "         ('minister', 'he'): 2,\n",
              "         ('he', 'said'): 1588,\n",
              "         ('said', '*end*'): 1982,\n",
              "         ('*start*', 'but'): 1381,\n",
              "         ('but', 'the'): 310,\n",
              "         ('minister', 'says'): 14,\n",
              "         ('says', 'letters'): 1,\n",
              "         ('letters', 'show'): 1,\n",
              "         ('show', 'he'): 1,\n",
              "         ('he', 'was'): 57,\n",
              "         ('was', '*UNK*'): 252,\n",
              "         ('*UNK*', 'about'): 177,\n",
              "         ('about', 'the'): 304,\n",
              "         ('the', 'future'): 164,\n",
              "         ('future', 'of'): 69,\n",
              "         ('of', 'wheat'): 60,\n",
              "         ('sales', 'in'): 11,\n",
              "         ('in', 'iraq'): 10,\n",
              "         ('iraq', 'and'): 6,\n",
              "         ('and', 'do'): 19,\n",
              "         ('do', 'not'): 99,\n",
              "         ('not', 'prove'): 3,\n",
              "         ('prove', 'the'): 5,\n",
              "         ('government', 'knew'): 1,\n",
              "         ('knew', 'of'): 2,\n",
              "         ('the', 'payments'): 7,\n",
              "         ('payments', '*end*'): 6,\n",
              "         ('*start*', 'it'): 1156,\n",
              "         ('it', 'would'): 136,\n",
              "         ('would', 'have'): 192,\n",
              "         ('been', '*UNK*'): 307,\n",
              "         ('*UNK*', 'in'): 1873,\n",
              "         ('2002', 'if'): 1,\n",
              "         ('if', 'as'): 3,\n",
              "         ('as', 'prime'): 1,\n",
              "         ('minister', 'i'): 1,\n",
              "         ('i', '*UNK*'): 173,\n",
              "         ('*UNK*', 'done'): 7,\n",
              "         ('done', 'anything'): 3,\n",
              "         ('anything', 'i'): 1,\n",
              "         ('i', 'possibly'): 1,\n",
              "         ('possibly', 'could'): 1,\n",
              "         ('could', 'to'): 2,\n",
              "         ('to', 'preserve'): 15,\n",
              "         ('preserve', 'australia'): 1,\n",
              "         ('australia', '*UNK*'): 582,\n",
              "         ('*UNK*', 'very'): 62,\n",
              "         ('very', 'valuable'): 1,\n",
              "         ('valuable', 'wheat'): 1,\n",
              "         ('wheat', 'market'): 9,\n",
              "         ('market', 'he'): 21,\n",
              "         ('*start*', 'email'): 1,\n",
              "         ('email', 'questions'): 1,\n",
              "         ('questions', 'today'): 1,\n",
              "         ('today', 'at'): 6,\n",
              "         ('the', 'inquiry'): 43,\n",
              "         ('inquiry', 'awb'): 3,\n",
              "         ('awb', 'trading'): 1,\n",
              "         ('trading', 'manager'): 1,\n",
              "         ('manager', 'peter'): 3,\n",
              "         ('peter', '*UNK*'): 120,\n",
              "         ('*UNK*', 'has'): 395,\n",
              "         ('has', 'been'): 837,\n",
              "         ('been', 'questioned'): 2,\n",
              "         ('questioned', 'about'): 2,\n",
              "         ('about', 'an'): 6,\n",
              "         ('an', 'email'): 5,\n",
              "         ('email', 'he'): 1,\n",
              "         ('he', 'received'): 6,\n",
              "         ('received', 'in'): 2,\n",
              "         ('in', 'may'): 11,\n",
              "         ('may', '2000'): 1,\n",
              "         ('2000', '*end*'): 7,\n",
              "         ('it', '*UNK*'): 1277,\n",
              "         ('*UNK*', 'that'): 737,\n",
              "         ('that', 'the'): 665,\n",
              "         ('the', 'iraqi'): 24,\n",
              "         ('iraqi', 'grains'): 11,\n",
              "         ('grains', 'board'): 12,\n",
              "         ('board', 'had'): 1,\n",
              "         ('had', '*UNK*'): 79,\n",
              "         ('*UNK*', 'awb'): 27,\n",
              "         ('awb', 'to'): 20,\n",
              "         ('to', 'provide'): 67,\n",
              "         ('provide', 'after'): 1,\n",
              "         ('after', 'sales'): 3,\n",
              "         ('sales', 'service'): 3,\n",
              "         ('service', '*end*'): 12,\n",
              "         ('*start*', 'mr'): 181,\n",
              "         ('mr', '*UNK*'): 203,\n",
              "         ('*UNK*', 'said'): 150,\n",
              "         ('said', 'he'): 15,\n",
              "         ('he', 'had'): 32,\n",
              "         ('*UNK*', 'the'): 2046,\n",
              "         ('the', 'email'): 9,\n",
              "         ('email', 'to'): 3,\n",
              "         ('to', 'two'): 16,\n",
              "         ('two', 'awb'): 1,\n",
              "         ('awb', 'colleagues'): 1,\n",
              "         ('colleagues', 'and'): 4,\n",
              "         ('and', 'did'): 9,\n",
              "         ('did', 'not'): 129,\n",
              "         ('not', 'remember'): 1,\n",
              "         ('remember', 'reading'): 1,\n",
              "         ('reading', 'it'): 1,\n",
              "         ('it', 'although'): 1,\n",
              "         ('although', 'he'): 6,\n",
              "         ('he', 'may'): 4,\n",
              "         ('may', 'have'): 157,\n",
              "         ('have', '*UNK*'): 340,\n",
              "         ('*UNK*', 'it'): 288,\n",
              "         ('it', '*end*'): 169,\n",
              "         ('*start*', 'support'): 1,\n",
              "         ('support', 'awb'): 2,\n",
              "         ('awb', 'still'): 5,\n",
              "         ('still', 'has'): 8,\n",
              "         ('has', 'plenty'): 1,\n",
              "         ('plenty', 'of'): 22,\n",
              "         ('of', 'support'): 7,\n",
              "         ('support', 'among'): 1,\n",
              "         ('among', 'grain'): 1,\n",
              "         ('grain', 'growers'): 69,\n",
              "         ('growers', 'in'): 64,\n",
              "         ('in', 'central'): 56,\n",
              "         ('central', 'western'): 15,\n",
              "         ('western', 'new'): 36,\n",
              "         ('new', 'south'): 421,\n",
              "         ('south', 'wales'): 421,\n",
              "         ('wales', 'despite'): 1,\n",
              "         ('despite', 'the'): 44,\n",
              "         ('*UNK*', 'of'): 2353,\n",
              "         ('inquiry', '*end*'): 43,\n",
              "         ('*start*', 'producers'): 10,\n",
              "         ('producers', 'say'): 4,\n",
              "         ('say', 'they'): 144,\n",
              "         ('they', '*UNK*'): 160,\n",
              "         ('*UNK*', 'support'): 15,\n",
              "         ('awb', '*UNK*'): 126,\n",
              "         ('*UNK*', 'attempts'): 4,\n",
              "         ('attempts', 'to'): 20,\n",
              "         ('to', 'get'): 288,\n",
              "         ('get', 'the'): 62,\n",
              "         ('the', 'best'): 125,\n",
              "         ('best', 'prices'): 2,\n",
              "         ('prices', 'for'): 36,\n",
              "         ('for', 'their'): 87,\n",
              "         ('their', 'products'): 6,\n",
              "         ('products', '*end*'): 15,\n",
              "         ('*start*', 'i'): 540,\n",
              "         ('i', 'think'): 323,\n",
              "         ('think', 'it'): 88,\n",
              "         ('*UNK*', 'all'): 69,\n",
              "         ('all', 'a'): 2,\n",
              "         ('*UNK*', 'by'): 511,\n",
              "         ('by', 'overseas'): 2,\n",
              "         ('overseas', 'interests'): 1,\n",
              "         ('interests', 'to'): 1,\n",
              "         ('to', 'try'): 103,\n",
              "         ('try', 'and'): 30,\n",
              "         ('and', 'get'): 25,\n",
              "         ('the', 'single'): 106,\n",
              "         ('single', 'desk'): 141,\n",
              "         ('desk', 'put'): 1,\n",
              "         ('put', 'aside'): 2,\n",
              "         ('aside', '*end*'): 1,\n",
              "         ('the', 'stories'): 2,\n",
              "         ('stories', 'that'): 2,\n",
              "         ('that', 'are'): 201,\n",
              "         ('are', 'going'): 64,\n",
              "         ('going', 'round'): 1,\n",
              "         ('round', 'about'): 1,\n",
              "         ('the', 'commission'): 21,\n",
              "         ('commission', 'and'): 3,\n",
              "         ('and', 'everything'): 7,\n",
              "         ('everything', 'i'): 1,\n",
              "         ('think', 'that'): 89,\n",
              "         ('that', '*UNK*'): 921,\n",
              "         ('the', 'way'): 144,\n",
              "         ('way', 'people'): 4,\n",
              "         ('people', 'have'): 67,\n",
              "         ('have', 'got'): 56,\n",
              "         ('got', 'to'): 61,\n",
              "         ('to', 'do'): 208,\n",
              "         ('do', 'things'): 3,\n",
              "         ('things', 'to'): 8,\n",
              "         ('do', 'business'): 5,\n",
              "         ('business', 'with'): 5,\n",
              "         ('the', 'middle'): 73,\n",
              "         ('middle', 'east'): 37,\n",
              "         ('east', 'and'): 8,\n",
              "         ('and', 'asian'): 1,\n",
              "         ('asian', 'countries'): 2,\n",
              "         ('countries', 'one'): 1,\n",
              "         ('one', 'producer'): 3,\n",
              "         ('producer', 'said'): 4,\n",
              "         ('*UNK*', 'actually'): 28,\n",
              "         ('actually', 'a'): 7,\n",
              "         ('a', 'pretty'): 7,\n",
              "         ('pretty', 'reasonable'): 2,\n",
              "         ('reasonable', 'system'): 1,\n",
              "         ('system', 'and'): 36,\n",
              "         ('and', 'i'): 119,\n",
              "         ('think', 'actually'): 1,\n",
              "         ('actually', 'i'): 2,\n",
              "         ('*UNK*', 'give'): 5,\n",
              "         ('give', 'them'): 14,\n",
              "         ('them', 'pretty'): 3,\n",
              "         ('pretty', 'fair'): 2,\n",
              "         ('fair', 'support'): 1,\n",
              "         ('support', 'at'): 2,\n",
              "         ('the', 'moment'): 110,\n",
              "         ('moment', '*end*'): 14,\n",
              "         ('think', 'on'): 2,\n",
              "         ('on', 'average'): 31,\n",
              "         ('average', 'they'): 1,\n",
              "         ('they', 've'): 111,\n",
              "         ('ve', 'performed'): 1,\n",
              "         ('performed', 'fairly'): 1,\n",
              "         ('fairly', 'well'): 2,\n",
              "         ('well', 'another'): 1,\n",
              "         ('another', 'producer'): 2,\n",
              "         ('the', 'biggest'): 89,\n",
              "         ('biggest', 'thing'): 3,\n",
              "         ('thing', 'about'): 9,\n",
              "         ('about', 'someone'): 1,\n",
              "         ('someone', 'else'): 10,\n",
              "         ('else', 'taking'): 1,\n",
              "         ('taking', 'over'): 2,\n",
              "         ('over', 'is'): 3,\n",
              "         ('is', 'whether'): 6,\n",
              "         ('whether', 'the'): 71,\n",
              "         ('*UNK*', 'will'): 203,\n",
              "         ('will', 'get'): 18,\n",
              "         ('get', 'too'): 5,\n",
              "         ('too', 'much'): 38,\n",
              "         ('much', 'of'): 55,\n",
              "         ('of', 'a'): 785,\n",
              "         ('in', 'there'): 18,\n",
              "         ('there', 'and'): 50,\n",
              "         ('and', 'take'): 9,\n",
              "         ('take', 'it'): 11,\n",
              "         ('it', 'too'): 4,\n",
              "         ('much', 'to'): 7,\n",
              "         ('to', 'their'): 89,\n",
              "         ('their', 'advantage'): 2,\n",
              "         ('advantage', '*end*'): 6,\n",
              "         ('*start*', 'grain'): 38,\n",
              "         ('grain', 'prices'): 30,\n",
              "         ('prices', 'but'): 5,\n",
              "         ('but', 'an'): 7,\n",
              "         ('an', 'analyst'): 1,\n",
              "         ('analyst', 'predicts'): 2,\n",
              "         ('predicts', 'grain'): 1,\n",
              "         ('prices', 'will'): 13,\n",
              "         ('will', 'drop'): 7,\n",
              "         ('drop', 'another'): 1,\n",
              "         ('another', '20'): 1,\n",
              "         ('20', 'a'): 3,\n",
              "         ('a', 'tonne'): 49,\n",
              "         ('tonne', 'on'): 3,\n",
              "         ('on', 'the'): 1263,\n",
              "         ('the', 'back'): 38,\n",
              "         ('back', 'of'): 27,\n",
              "         ('into', 'awb'): 9,\n",
              "         ('awb', '*end*'): 23,\n",
              "         ('*start*', 'malcolm'): 5,\n",
              "         ('malcolm', '*UNK*'): 15,\n",
              "         ('*UNK*', 'says'): 2341,\n",
              "         ('says', 'pool'): 1,\n",
              "         ('pool', 'returns'): 9,\n",
              "         ('returns', 'have'): 1,\n",
              "         ('have', 'already'): 36,\n",
              "         ('already', 'dropped'): 1,\n",
              "         ('dropped', 'by'): 4,\n",
              "         ('by', '20'): 12,\n",
              "         ('tonne', 'this'): 2,\n",
              "         ('this', 'year'): 281,\n",
              "         ('year', 'from'): 5,\n",
              "         ('from', 'the'): 1355,\n",
              "         ('the', 'average'): 32,\n",
              "         ('average', 'price'): 9,\n",
              "         ('price', 'over'): 2,\n",
              "         ('over', 'the'): 378,\n",
              "         ('the', 'past'): 228,\n",
              "         ('past', 'five'): 11,\n",
              "         ('five', 'years'): 79,\n",
              "         ('years', '*end*'): 207,\n",
              "         ('that', 'awb'): 15,\n",
              "         ('*UNK*', 'through'): 80,\n",
              "         ('through', 'its'): 5,\n",
              "         ('its', 'wheat'): 7,\n",
              "         ('wheat', 'export'): 60,\n",
              "         ('export', 'monopoly'): 5,\n",
              "         ('monopoly', 'have'): 1,\n",
              "         ('been', 'severely'): 2,\n",
              "         ('severely', 'eroded'): 1,\n",
              "         ('eroded', '*end*'): 1,\n",
              "         ('*start*', 'sa'): 16,\n",
              "         ('sa', 'farmers'): 3,\n",
              "         ('farmers', 'help'): 1,\n",
              "         ('help', 'fire'): 2,\n",
              "         ('fire', '*UNK*'): 17,\n",
              "         ('*UNK*', 'neighbours'): 2,\n",
              "         ('neighbours', 'farmers'): 1,\n",
              "         ('farmers', 'in'): 81,\n",
              "         ('in', 'south'): 157,\n",
              "         ('south', 'australia'): 212,\n",
              "         ('*UNK*', 'south'): 68,\n",
              "         ('south', 'east'): 77,\n",
              "         ('east', 'are'): 4,\n",
              "         ('are', '*UNK*'): 525,\n",
              "         ('of', 'hay'): 8,\n",
              "         ('hay', 'to'): 2,\n",
              "         ('their', 'neighbours'): 4,\n",
              "         ('neighbours', 'across'): 1,\n",
              "         ('across', 'the'): 138,\n",
              "         ('the', 'border'): 13,\n",
              "         ('border', 'in'): 1,\n",
              "         ('in', 'the'): 3913,\n",
              "         ('the', 'wake'): 42,\n",
              "         ('wake', 'of'): 42,\n",
              "         ('*UNK*', 'bushfires'): 3,\n",
              "         ('bushfires', '*end*'): 8,\n",
              "         ('in', 'just'): 14,\n",
              "         ('just', 'a'): 58,\n",
              "         ('a', 'few'): 133,\n",
              "         ('few', 'days'): 14,\n",
              "         ('days', 'farmers'): 1,\n",
              "         ('farmers', 'have'): 65,\n",
              "         ('have', 'donated'): 3,\n",
              "         ('donated', '250'): 1,\n",
              "         ('250', 'tonnes'): 1,\n",
              "         ('tonnes', 'of'): 111,\n",
              "         ('hay', 'as'): 1,\n",
              "         ('as', 'well'): 205,\n",
              "         ('well', 'as'): 115,\n",
              "         ('as', '*UNK*'): 351,\n",
              "         ('*UNK*', 'for'): 715,\n",
              "         ('for', 'cattle'): 11,\n",
              "         ('cattle', '*end*'): 21,\n",
              "         ('*start*', 'they'): 610,\n",
              "         ('they', 'say'): 103,\n",
              "         ('say', 'that'): 57,\n",
              "         ('that', 'is'): 276,\n",
              "         ('is', 'just'): 57,\n",
              "         ('just', 'the'): 21,\n",
              "         ('the', 'beginning'): 18,\n",
              "         ('beginning', '*end*'): 3,\n",
              "         ('*start*', 'fodder'): 4,\n",
              "         ('fodder', 'drive'): 1,\n",
              "         ('drive', 'coordinator'): 1,\n",
              "         ('coordinator', 'peter'): 1,\n",
              "         ('says', 'he'): 241,\n",
              "         ('he', 'has'): 78,\n",
              "         ('the', 'response'): 12,\n",
              "         ('response', '*end*'): 17,\n",
              "         ('*start*', 'all'): 65,\n",
              "         ('all', 'the'): 142,\n",
              "         ('the', 'hay'): 6,\n",
              "         ('hay', 'that'): 1,\n",
              "         ('*UNK*', 'going'): 86,\n",
              "         ('going', 'this'): 1,\n",
              "         ('this', 'week'): 227,\n",
              "         ('week', 'has'): 9,\n",
              "         ('has', 'all'): 4,\n",
              "         ('all', 'gone'): 1,\n",
              "         ('gone', 'from'): 4,\n",
              "         ('from', 'places'): 3,\n",
              "         ('places', 'that'): 6,\n",
              "         ('that', 'have'): 98,\n",
              "         ('donated', 'one'): 1,\n",
              "         ('one', 'load'): 1,\n",
              "         ('load', 'or'): 1,\n",
              "         ('or', 'up'): 1,\n",
              "         ('up', 'to'): 351,\n",
              "         ('two', 'loads'): 1,\n",
              "         ('loads', 'of'): 5,\n",
              "         ('hay', 'he'): 1,\n",
              "         ('*start*', 'we'): 936,\n",
              "         ('we', 've'): 323,\n",
              "         ('ve', 'got'): 137,\n",
              "         ('got', 'one'): 5,\n",
              "         ('one', 'man'): 3,\n",
              "         ('man', 'that'): 1,\n",
              "         ('*UNK*', 'donated'): 1,\n",
              "         ('donated', 'two'): 1,\n",
              "         ('two', 'full'): 1,\n",
              "         ('full', 'loads'): 1,\n",
              "         ('loads', 'and'): 2,\n",
              "         ('the', 'rest'): 42,\n",
              "         ('rest', 'are'): 1,\n",
              "         ('are', 'all'): 13,\n",
              "         ('all', 'one'): 1,\n",
              "         ('one', 'loads'): 1,\n",
              "         ('loads', 'straight'): 1,\n",
              "         ('straight', 'loads'): 1,\n",
              "         ('loads', 'that'): 1,\n",
              "         ('that', 'we'): 306,\n",
              "         ('we', 're'): 338,\n",
              "         ('re', 'moving'): 2,\n",
              "         ('moving', 'this'): 1,\n",
              "         ('week', '*end*'): 127,\n",
              "         ('*start*', '*UNK*'): 2433,\n",
              "         ('*UNK*', 'close'): 15,\n",
              "         ('close', 'highway'): 1,\n",
              "         ('highway', 'a'): 1,\n",
              "         ('a', 'major'): 128,\n",
              "         ('major', 'highway'): 2,\n",
              "         ('highway', 'between'): 2,\n",
              "         ('between', 'the'): 111,\n",
              "         ('the', 'northern'): 176,\n",
              "         ('northern', 'territory'): 132,\n",
              "         ('territory', 'and'): 6,\n",
              "         ('and', 'western'): 20,\n",
              "         ('western', 'australia'): 233,\n",
              "         ('australia', 'remains'): 2,\n",
              "         ('remains', '*UNK*'): 10,\n",
              "         ('by', '*UNK*'): 392,\n",
              "         ('*UNK*', 'today'): 27,\n",
              "         ('today', '*end*'): 95,\n",
              "         ('the', 'victoria'): 9,\n",
              "         ('victoria', 'river'): 5,\n",
              "         ('river', 'has'): 7,\n",
              "         ('has', 'cut'): 10,\n",
              "         ('cut', 'the'): 18,\n",
              "         ('victoria', 'highway'): 2,\n",
              "         ('highway', 'and'): 1,\n",
              "         ('and', 'also'): 35,\n",
              "         ('also', 'flooded'): 1,\n",
              "         ('flooded', 'the'): 2,\n",
              "         ('the', 'remote'): 11,\n",
              "         ('remote', '*UNK*'): 9,\n",
              "         ('*UNK*', 'hole'): 4,\n",
              "         ('hole', 'aboriginal'): 1,\n",
              "         ('aboriginal', 'community'): 9,\n",
              "         ('community', '*end*'): 23,\n",
              "         ('*UNK*', 'simon'): 3,\n",
              "         ('simon', '*UNK*'): 16,\n",
              "         ('*UNK*', 'describes'): 12,\n",
              "         ('describes', 'the'): 18,\n",
              "         ('a', 'hundred'): 13,\n",
              "         ('hundred', 'people'): 4,\n",
              "         ('people', 'to'): 61,\n",
              "         ('to', 'higher'): 8,\n",
              "         ('higher', 'ground'): 2,\n",
              "         ('ground', '*end*'): 24,\n",
              "         ('they', 'had'): 65,\n",
              "         ('had', 'all'): 4,\n",
              "         ('all', 'their'): 5,\n",
              "         ('their', 'vehicles'): 4,\n",
              "         ('vehicles', 'moved'): 1,\n",
              "         ('moved', 'out'): 2,\n",
              "         ('out', 'of'): 270,\n",
              "         ('the', 'community'): 48,\n",
              "         ('community', 'and'): 6,\n",
              "         ('and', 'they'): 160,\n",
              "         ('had', 'a'): 128,\n",
              "         ('few', '*UNK*'): 23,\n",
              "         ('*UNK*', 'set'): 16,\n",
              "         ('set', 'up'): 74,\n",
              "         ('up', 'and'): 63,\n",
              "         ('they', 'were'): 156,\n",
              "         ('were', 'moving'): 2,\n",
              "         ('moving', 'more'): 1,\n",
              "         ('more', 'people'): 15,\n",
              "         ('people', 'and'): 40,\n",
              "         ('and', '*UNK*'): 2294,\n",
              "         ('*UNK*', 'out'): 207,\n",
              "         ('out', 'with'): 23,\n",
              "         ('with', 'a'): 425,\n",
              "         ('a', 'couple'): 46,\n",
              "         ('couple', 'of'): 61,\n",
              "         ('of', 'boats'): 2,\n",
              "         ('boats', 'just'): 1,\n",
              "         ('just', 'onto'): 1,\n",
              "         ('onto', 'higher'): 1,\n",
              "         ('ground', 'only'): 1,\n",
              "         ('only', '500'): 1,\n",
              "         ('500', 'metres'): 4,\n",
              "         ('metres', 'from'): 2,\n",
              "         ('community', 'he'): 5,\n",
              "         ('they', 'are'): 419,\n",
              "         ('are', 'up'): 18,\n",
              "         ('up', 'on'): 31,\n",
              "         ('on', 'a'): 265,\n",
              "         ('moment', 'and'): 10,\n",
              "         ('think', 'the'): 84,\n",
              "         ('the', 'river'): 45,\n",
              "         ('river', '*UNK*'): 21,\n",
              "         ('*UNK*', 'might'): 33,\n",
              "         ('might', 'be'): 101,\n",
              "         ('be', 'up'): 12,\n",
              "         ('up', 'for'): 35,\n",
              "         ('for', 'a'): 352,\n",
              "         ('a', 'little'): 89,\n",
              "         ('little', 'longer'): 2,\n",
              "         ('longer', 'but'): 1,\n",
              "         ('but', 'i'): 54,\n",
              "         ('it', 'the'): 22,\n",
              "         ('river', 'will'): 6,\n",
              "         ('will', 'start'): 21,\n",
              "         ('start', 'going'): 2,\n",
              "         ('going', 'down'): 3,\n",
              "         ('down', '*end*'): 30,\n",
              "         ('grain', 'company'): 2,\n",
              "         ('company', 'sold'): 1,\n",
              "         ('sold', 'for'): 19,\n",
              "         ('for', '*UNK*'): 506,\n",
              "         ('*UNK*', 'tasmania'): 7,\n",
              "         ('tasmania', '*UNK*'): 53,\n",
              "         ('*UNK*', 'main'): 12,\n",
              "         ('main', 'grain'): 3,\n",
              "         ('company', 'has'): 38,\n",
              "         ('has', 'changed'): 7,\n",
              "         ('changed', 'hands'): 2,\n",
              "         ('hands', 'for'): 1,\n",
              "         ('for', 'the'): 1015,\n",
              "         ('the', 'second'): 71,\n",
              "         ('second', 'time'): 4,\n",
              "         ('time', 'in'): 56,\n",
              "         ('just', 'three'): 7,\n",
              "         ('three', 'years'): 72,\n",
              "         ('the', 'former'): 20,\n",
              "         ('former', 'state'): 1,\n",
              "         ('state', 'owned'): 2,\n",
              "         ('owned', 'tasmanian'): 1,\n",
              "         ('tasmanian', 'grain'): 3,\n",
              "         ('grain', '*UNK*'): 21,\n",
              "         ('*UNK*', 'board'): 9,\n",
              "         ('board', 'has'): 5,\n",
              "         ('been', 'sold'): 10,\n",
              "         ('sold', 'to'): 13,\n",
              "         ('to', 'local'): 10,\n",
              "         ('local', 'agribusiness'): 1,\n",
              "         ('agribusiness', 'roberts'): 2,\n",
              "         ('roberts', 'limited'): 6,\n",
              "         ('limited', 'for'): 2,\n",
              "         ('for', 'about'): 21,\n",
              "         ('about', '*UNK*'): 193,\n",
              "         ('the', 'deal'): 28,\n",
              "         ('deal', 'includes'): 1,\n",
              "         ('includes', 'silos'): 1,\n",
              "         ('silos', 'at'): 1,\n",
              "         ('at', '*UNK*'): 442,\n",
              "         ('*UNK*', 'and'): 3154,\n",
              "         ('in', 'northern'): 42,\n",
              "         ('northern', 'tasmania'): 10,\n",
              "         ('tasmania', '*end*'): 21,\n",
              "         ('*start*', 'john'): 34,\n",
              "         ('john', '*UNK*'): 118,\n",
              "         ('*UNK*', 'from'): 1031,\n",
              "         ('from', 'roberts'): 3,\n",
              "         ('limited', 'says'): 7,\n",
              "         ('the', 'company'): 223,\n",
              "         ('company', 'bid'): 1,\n",
              "         ('bid', 'when'): 1,\n",
              "         ('when', 'the'): 175,\n",
              "         ('the', 'board'): 20,\n",
              "         ('board', 'was'): 2,\n",
              "         ('was', 'first'): 16,\n",
              "         ('first', '*UNK*'): 66,\n",
              "         ('*UNK*', '*end*'): 4401,\n",
              "         ('we', 'were'): 60,\n",
              "         ('were', 'very'): 14,\n",
              "         ('very', 'disappointed'): 4,\n",
              "         ('disappointed', 'we'): 1,\n",
              "         ('we', 'weren'): 9,\n",
              "         ('weren', '*UNK*'): 25,\n",
              "         ('*UNK*', 'successful'): 3,\n",
              "         ('successful', 'at'): 1,\n",
              "         ('at', 'that'): 21,\n",
              "         ('that', 'point'): 5,\n",
              "         ('point', 'of'): 21,\n",
              "         ('of', 'time'): 36,\n",
              "         ('time', 'he'): 14,\n",
              "         ('*start*', 'wine'): 18,\n",
              "         ('wine', 'workers'): 1,\n",
              "         ('workers', 'stop'): 1,\n",
              "         ('stop', 'work'): 1,\n",
              "         ('work', 'workers'): 1,\n",
              "         ('workers', 'at'): 13,\n",
              "         ('*UNK*', 'wines'): 11,\n",
              "         ('wines', 'stanley'): 1,\n",
              "         ('stanley', '*UNK*'): 3,\n",
              "         ('south', 'western'): 2,\n",
              "         ('wales', 'have'): 18,\n",
              "         ('have', 'walked'): 1,\n",
              "         ('walked', 'off'): 3,\n",
              "         ('off', 'the'): 94,\n",
              "         ('the', 'job'): 20,\n",
              "         ('job', 'for'): 4,\n",
              "         ('in', 'a'): 737,\n",
              "         ('a', 'week'): 29,\n",
              "         ('*UNK*', 'staff'): 10,\n",
              "         ('staff', 'walked'): 1,\n",
              "         ('walked', 'out'): 2,\n",
              "         ('out', 'this'): 6,\n",
              "         ('this', 'morning'): 35,\n",
              "         ('morning', 'in'): 4,\n",
              "         ('a', 'dispute'): 8,\n",
              "         ('dispute', 'over'): 7,\n",
              "         ('over', 'a'): 62,\n",
              "         ('a', 'new'): 471,\n",
              "         ('new', '*UNK*'): 141,\n",
              "         ('*UNK*', 'bargaining'): 5,\n",
              "         ('bargaining', 'agreement'): 2,\n",
              "         ('agreement', '*end*'): 12,\n",
              "         ('*UNK*', 'comes'): 15,\n",
              "         ('comes', 'just'): 4,\n",
              "         ('just', 'as'): 34,\n",
              "         ('as', 'the'): 332,\n",
              "         ('the', 'region'): 96,\n",
              "         ('region', '*UNK*'): 19,\n",
              "         ('*UNK*', 'wine'): 16,\n",
              "         ('wine', 'grape'): 22,\n",
              "         ('grape', 'crush'): 2,\n",
              "         ('crush', 'gets'): 1,\n",
              "         ('gets', 'under'): 1,\n",
              "         ('under', 'way'): 60,\n",
              "         ('way', '*end*'): 42,\n",
              "         ('wines', 'took'): 1,\n",
              "         ('took', 'the'): 13,\n",
              "         ('the', 'matter'): 11,\n",
              "         ('matter', 'to'): 3,\n",
              "         ('the', 'industrial'): 6,\n",
              "         ('industrial', 'relations'): 6,\n",
              "         ('relations', 'commission'): 1,\n",
              "         ('commission', '*UNK*'): 21,\n",
              "         ('*UNK*', 'on'): 593,\n",
              "         ('on', 'friday'): 19,\n",
              "         ('friday', '*end*'): 8,\n",
              "         ('*start*', 'wool'): 41,\n",
              "         ('wool', 'body'): 2,\n",
              "         ('body', 'eyes'): 1,\n",
              "         ('eyes', '*UNK*'): 3,\n",
              "         ('*UNK*', 'industry'): 57,\n",
              "         ('industry', 'the'): 18,\n",
              "         ('the', '50'): 5,\n",
              "         ('50', 'billion'): 3,\n",
              "         ('billion', 'global'): 1,\n",
              "         ('global', '*UNK*'): 14,\n",
              "         ('industry', 'is'): 89,\n",
              "         ('is', 'the'): 474,\n",
              "         ('the', 'new'): 401,\n",
              "         ('new', 'target'): 1,\n",
              "         ('target', 'of'): 6,\n",
              "         ('of', 'wool'): 28,\n",
              "         ('wool', 'promotion'): 1,\n",
              "         ('promotion', 'body'): 1,\n",
              "         ('body', 'australian'): 5,\n",
              "         ('australian', 'wool'): 73,\n",
              "         ('wool', 'innovation'): 37,\n",
              "         ('innovation', 'awi'): 17,\n",
              "         ('awi', '*end*'): 8,\n",
              "         ('*start*', 'awi'): 14,\n",
              "         ('awi', 'is'): 2,\n",
              "         ('is', 'showing'): 7,\n",
              "         ('showing', 'wool'): 1,\n",
              "         ('wool', 'blend'): 2,\n",
              "         ('blend', '*UNK*'): 3,\n",
              "         ('*UNK*', 'wear'): 2,\n",
              "         ('wear', 'to'): 1,\n",
              "         ('to', 'manufacturers'): 2,\n",
              "         ('manufacturers', 'this'): 1,\n",
              "         ('week', 'at'): 22,\n",
              "         ('the', 'largest'): 57,\n",
              "         ('largest', 'trade'): 1,\n",
              "         ('trade', 'show'): 1,\n",
              "         ('show', 'for'): 3,\n",
              "         ('the', 'industry'): 201,\n",
              "         ('industry', 'being'): 2,\n",
              "         ('being', 'held'): 8,\n",
              "         ('held', 'in'): 20,\n",
              "         ('in', 'germany'): 12,\n",
              "         ('germany', '*end*'): 8,\n",
              "         ('awi', '*UNK*'): 7,\n",
              "         ('*UNK*', 'stephens'): 8,\n",
              "         ('stephens', 'says'): 6,\n",
              "         ('says', 'although'): 19,\n",
              "         ('although', 'wool'): 1,\n",
              "         ('will', 'be'): 733,\n",
              "         ('be', 'at'): 25,\n",
              "         ('*UNK*', 'end'): 13,\n",
              "         ('end', 'of'): 134,\n",
              "         ('the', 'market'): 137,\n",
              "         ('market', 'shoppers'): 1,\n",
              "         ('shoppers', 'are'): 2,\n",
              "         ('are', 'willing'): 5,\n",
              "         ('willing', 'to'): 21,\n",
              "         ('to', 'pay'): 72,\n",
              "         ('pay', 'more'): 18,\n",
              "         ('more', '*end*'): 29,\n",
              "         ('the', 'sports'): 2,\n",
              "         ('sports', '*UNK*'): 7,\n",
              "         ('*UNK*', 'market'): 23,\n",
              "         ('market', 'sector'): 1,\n",
              "         ('sector', 'is'): 12,\n",
              "         ('is', 'one'): 77,\n",
              "         ('biggest', 'and'): 6,\n",
              "         ('and', 'certainly'): 5,\n",
              "         ('certainly', 'the'): 10,\n",
              "         ('*UNK*', 'growing'): 12,\n",
              "         ('growing', '*UNK*'): 10,\n",
              "         ('*UNK*', 'sector'): 5,\n",
              "         ('sector', 'in'): 6,\n",
              "         ('the', 'world'): 394,\n",
              "         ('world', 'and'): 17,\n",
              "         ('and', 'it'): 194,\n",
              "         ('*UNK*', 'no'): 85,\n",
              "         ('no', 'secret'): 1,\n",
              "         ('secret', 'that'): 1,\n",
              "         ('that', 'wool'): 4,\n",
              "         ('wool', 'hasn'): 1,\n",
              "         ('hasn', '*UNK*'): 44,\n",
              "         ('*UNK*', 'had'): 93,\n",
              "         ('a', 'very'): 170,\n",
              "         ('very', 'big'): 6,\n",
              "         ('big', 'share'): 1,\n",
              "         ('share', 'of'): 15,\n",
              "         ('of', 'that'): 66,\n",
              "         ('that', 'market'): 9,\n",
              "         ('market', 'at'): 2,\n",
              "         ('at', 'all'): 69,\n",
              "         ('all', 'he'): 11,\n",
              "         ('the', 'level'): 27,\n",
              "         ('level', 'of'): 58,\n",
              "         ('wool', 'particularly'): 1,\n",
              "         ('particularly', 'australian'): 1,\n",
              "         ('australian', 'merino'): 1,\n",
              "         ('merino', 'wool'): 3,\n",
              "         ('wool', 'in'): 11,\n",
              "         ('sports', 'market'): 1,\n",
              "         ('market', 'is'): 22,\n",
              "         ('is', 'really'): 33,\n",
              "         ('really', 'almost'): 1,\n",
              "         ('almost', 'below'): 1,\n",
              "         ('below', 'the'): 27,\n",
              "         ('the', 'radar'): 3,\n",
              "         ('radar', '*end*'): 3,\n",
              "         ('*start*', 'organisation'): 1,\n",
              "         ('organisation', 'to'): 4,\n",
              "         ('to', 'step'): 11,\n",
              "         ('step', 'up'): 10,\n",
              "         ('up', '*UNK*'): 67,\n",
              "         ('*UNK*', 'campaign'): 6,\n",
              "         ('campaign', 'tasmania'): 1,\n",
              "         ('*UNK*', 'rodeo'): 4,\n",
              "         ('rodeo', 'industry'): 1,\n",
              "         ('is', 'under'): 37,\n",
              "         ('under', '*UNK*'): 15,\n",
              "         ('*UNK*', 'attack'): 4,\n",
              "         ('attack', 'from'): 2,\n",
              "         ('from', 'animal'): 4,\n",
              "         ('animal', 'rights'): 24,\n",
              "         ('rights', 'activists'): 4,\n",
              "         ('activists', 'after'): 1,\n",
              "         ('after', 'another'): 4,\n",
              "         ('another', 'animal'): 1,\n",
              "         ('animal', 'had'): 2,\n",
              "         ('had', 'to'): 73,\n",
              "         ('be', 'destroyed'): 8,\n",
              "         ('destroyed', 'at'): 3,\n",
              "         ('at', 'a'): 244,\n",
              "         ('a', 'weekend'): 7,\n",
              "         ('weekend', 'event'): 1,\n",
              "         ('event', '*end*'): 18,\n",
              "         ('*start*', 'a'): 524,\n",
              "         ('*UNK*', 'horse'): 9,\n",
              "         ('horse', 'was'): 2,\n",
              "         ('was', 'put'): 7,\n",
              "         ('put', 'down'): 6,\n",
              "         ('down', 'after'): 4,\n",
              "         ('after', 'breaking'): 2,\n",
              "         ('breaking', 'a'): 1,\n",
              "         ('a', 'leg'): 4,\n",
              "         ('leg', 'at'): 2,\n",
              "         ('on', 'saturday'): 11,\n",
              "         ('saturday', '*end*'): 5,\n",
              "         ('*start*', 'two'): 48,\n",
              "         ('two', 'weeks'): 35,\n",
              "         ('weeks', 'ago'): 22,\n",
              "         ('ago', 'a'): 8,\n",
              "         ('a', 'bull'): 6,\n",
              "         ('bull', 'was'): 3,\n",
              "         ('was', 'destroyed'): 2,\n",
              "         ('destroyed', 'after'): 2,\n",
              "         ('after', 'apparently'): 1,\n",
              "         ('apparently', 'breaking'): 1,\n",
              "         ('breaking', 'its'): 2,\n",
              "         ('its', 'back'): 5,\n",
              "         ('back', 'during'): 1,\n",
              "         ('during', 'a'): 35,\n",
              "         ('bull', 'riding'): 1,\n",
              "         ('riding', 'competition'): 1,\n",
              "         ('competition', 'at'): 6,\n",
              "         ('the', 'owner'): 10,\n",
              "         ('owner', 'of'): 7,\n",
              "         ('of', 'both'): 22,\n",
              "         ('both', 'animals'): 1,\n",
              "         ('animals', 'brian'): 1,\n",
              "         ('brian', 'fish'): 1,\n",
              "         ('fish', 'says'): 5,\n",
              "         ('says', 'they'): 72,\n",
              "         ('were', '*UNK*'): 171,\n",
              "         ('and', 'not'): 64,\n",
              "         ('not', 'an'): 17,\n",
              "         ('an', 'animal'): 23,\n",
              "         ('animal', 'welfare'): 33,\n",
              "         ('welfare', 'issue'): 1,\n",
              "         ('issue', '*end*'): 23,\n",
              "         ('but', '*UNK*'): 200,\n",
              "         ('from', 'against'): 1,\n",
              "         ('against', 'animal'): 3,\n",
              "         ('animal', 'cruelty'): 10,\n",
              "         ('cruelty', 'tasmania'): 2,\n",
              "         ('tasmania', 'says'): 8,\n",
              "         ('says', 'her'): 22,\n",
              "         ('her', 'organisation'): 4,\n",
              "         ('organisation', 'will'): 1,\n",
              "         ('will', 'up'): 1,\n",
              "         ('up', 'its'): 12,\n",
              "         ('its', 'efforts'): 4,\n",
              "         ('efforts', 'to'): 22,\n",
              "         ('to', 'have'): 360,\n",
              "         ('*UNK*', 'banned'): 3,\n",
              "         ('banned', '*end*'): 3,\n",
              "         ('*start*', 'snails'): 1,\n",
              "         ('snails', 'used'): 1,\n",
              "         ('used', 'in'): 99,\n",
              "         ('in', 'cancer'): 6,\n",
              "         ('cancer', 'research'): 5,\n",
              "         ('research', 'new'): 5,\n",
              "         ('new', 'research'): 80,\n",
              "         ('research', 'is'): 44,\n",
              "         ('way', 'to'): 97,\n",
              "         ('to', 'investigate'): 40,\n",
              "         ('investigate', 'whether'): 5,\n",
              "         ('whether', 'south'): 1,\n",
              "         ('south', 'australian'): 76,\n",
              "         ('australian', 'sea'): 1,\n",
              "         ('sea', 'snails'): 2,\n",
              "         ('snails', 'could'): 2,\n",
              "         ('could', 'eventually'): 10,\n",
              "         ('eventually', 'be'): 3,\n",
              "         ('be', 'used'): 179,\n",
              "         ('used', 'to'): 242,\n",
              "         ('to', 'treat'): 32,\n",
              "         ('treat', 'cancer'): 3,\n",
              "         ('cancer', '*end*'): 30,\n",
              "         ('*start*', 'until'): 34,\n",
              "         ('until', 'now'): 43,\n",
              "         ('now', 'the'): 33,\n",
              "         ('the', 'state'): 283,\n",
              "         ('state', '*UNK*'): 139,\n",
              "         ('*UNK*', 'snail'): 2,\n",
              "         ('snail', 'population'): 1,\n",
              "         ('population', 'has'): 3,\n",
              "         ('been', 'virtually'): 2,\n",
              "         ('virtually', '*UNK*'): 10,\n",
              "         ('*UNK*', 'but'): 252,\n",
              "         ('but', 'flinders'): 1,\n",
              "         ('flinders', 'university'): 10,\n",
              "         ('university', 'hopes'): 1,\n",
              "         ...})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "b_model.bigram_voc_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNmFtlkwkFQb"
      },
      "source": [
        "All of the above can be done with a trigram model. We just have to create an instance of it: tri_model = Model(type='trigram')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su8qOBZ9kFQb"
      },
      "source": [
        "### Hyper-parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoYLY6ngkFQb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sents, test_set, _, _ = train_test_split(sentences, sentences, test_size=0.2, random_state=42)  # keep test set \n",
        "train_set, dev_set, _, _ = train_test_split(train_sents, train_sents, test_size=0.1, random_state=42)  # split the train set to dev and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJwRYqXmkFQb"
      },
      "outputs": [],
      "source": [
        "bi_model = LM(n_type='bigram')\n",
        "bi_model.train(train_set)\n",
        "\n",
        "tri_model = LM(n_type='trigram')\n",
        "tri_model.train(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxGjzeX0kFQc",
        "outputId": "43d954e4-b813-4e15-f4d2-7a027b23ab77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best a for the bigram model: 0.010000000000000002\n"
          ]
        }
      ],
      "source": [
        "a = []\n",
        "cr_entr = []\n",
        "\n",
        "for i in np.arange(0.001, 1.001, 0.001):\n",
        "    hc, pp = bi_model.entr_perp(dev_set, a=i)\n",
        "    a.append(i)\n",
        "    cr_entr.append(hc)\n",
        "\n",
        "print(f'Best a for the bigram model: {a[np.argmin(cr_entr)]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxBjCXTYkFQc",
        "outputId": "095eac0b-2b8f-4a45-c9fc-c8217cf5061f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best a for the trigram model: 0.007\n"
          ]
        }
      ],
      "source": [
        "a = []\n",
        "cr_entr = []\n",
        "\n",
        "for i in np.arange(0.001, 1.001, 0.001):\n",
        "    hc, pp = tri_model.entr_perp(dev_set, a=i)\n",
        "    a.append(i)\n",
        "    cr_entr.append(hc)\n",
        "\n",
        "print(f'Best a for the trigram model: {a[np.argmin(cr_entr)]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpwSxuAikFQd",
        "outputId": "30b84866-99df-43b3-a976-2e8550cecfec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Entropy and Perplexity using the Bigram Model with Add-a Smoothing: 6.8930890717714455 and 118.8574951123271\n",
            "Cross-Entropy and Perplexity using the Bigram Model with K-N Smoothing: 6.529238290883772 and 92.3626903053094\n",
            "Cross-Entropy and Perplexity using the Trigram Model with Add-a Smoothing: 8.728574636695134 and 424.1923040644523\n"
          ]
        }
      ],
      "source": [
        "lap_hc, lap_pp = bi_model.entr_perp(test_set, a=0.01)\n",
        "kn_hc, kn_pp = bi_model.entr_perp(test_set, smoothing='kn')\n",
        "tri_hc, tri_pp = tri_model.entr_perp(test_set, a=0.007)\n",
        "\n",
        "print(f\"Cross-Entropy and Perplexity using the Bigram Model with Add-a Smoothing: {lap_hc} and {lap_pp}\")\n",
        "print(f\"Cross-Entropy and Perplexity using the Bigram Model with K-N Smoothing: {kn_hc} and {kn_pp}\")\n",
        "print(f\"Cross-Entropy and Perplexity using the Trigram Model with Add-a Smoothing: {tri_hc} and {tri_pp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUhT_TFtkFQd"
      },
      "outputs": [],
      "source": [
        "from random import shuffle\n",
        "test_shfl = test_set[:]\n",
        "foo = [shuffle(sent) for sent in test_shfl]  # shuffle the order of words from each sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXuLJdF2kFQd",
        "outputId": "22b24f16-ebaf-41d0-a677-a37ab3896f90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Entropy and Perplexity using the Bigram Model with Add-a Smoothing on shuffled sentences: 9.550154295720343 and 749.6920513343857\n",
            "Cross-Entropy and Perplexity using the Bigram Model with K-N Smoothing on shuffled sentences: 8.386838674787834 and 334.72643331454844\n",
            "Cross-Entropy and Perplexity using the Trigram Model with Add-a Smoothing on shuffled sentences: 10.894391388165639 and 1903.4373735979686\n"
          ]
        }
      ],
      "source": [
        "lap_hc, lap_pp = bi_model.entr_perp(test_shfl, a=0.01)\n",
        "kn_hc, kn_pp = bi_model.entr_perp(test_shfl, smoothing='kn')\n",
        "tri_hc, tri_pp = tri_model.entr_perp(test_shfl, a=0.007)\n",
        "\n",
        "print(f\"Cross-Entropy and Perplexity using the Bigram Model with Add-a Smoothing on shuffled sentences: {lap_hc} and {lap_pp}\")\n",
        "print(f\"Cross-Entropy and Perplexity using the Bigram Model with K-N Smoothing on shuffled sentences: {kn_hc} and {kn_pp}\")\n",
        "print(f\"Cross-Entropy and Perplexity using the Trigram Model with Add-a Smoothing on shuffled sentences: {tri_hc} and {tri_pp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gbCKO2KkFQe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def following_bi(word, model, smoother='kn', a=1):  # This function will return the top 10 most probable word continuations\n",
        "    voc = list(model.unigram_voc_.keys())\n",
        "    voc.remove('*start*')\n",
        "    voc.remove('*UNK*')\n",
        "    voc.remove('*end*')\n",
        "    \n",
        "    if smoother == 'kn':\n",
        "        next_word = {key: bi_model.kn_prob((word, key)) for key in voc}\n",
        "    else:\n",
        "        next_word = {key: bi_model.estimate_ngram_prob((word, key), a=a) for key in voc}\n",
        "\n",
        "    sorted_words = dict(sorted(next_word.items(), key=lambda item: item[1]))\n",
        "    top10 = {i: sorted_words[i] for i in list(sorted_words.keys())[-10:]}\n",
        "\n",
        "    return pd.DataFrame(top10.items()).rename(columns = {0: word, 1: 'Probability'}).sort_values(by='Probability', ascending=False)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6fwMpEc8kFQe",
        "outputId": "a13490f6-12d9-497f-e683-bf136af07ffc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ce96f3b3-6efa-4cb9-95e0-8fb24d553969\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>he</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>said</td>\n",
              "      <td>0.393450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>says</td>\n",
              "      <td>0.334239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>is</td>\n",
              "      <td>0.042016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>has</td>\n",
              "      <td>0.019870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>was</td>\n",
              "      <td>0.014306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>will</td>\n",
              "      <td>0.012981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>s</td>\n",
              "      <td>0.012233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>had</td>\n",
              "      <td>0.008396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>and</td>\n",
              "      <td>0.007996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>also</td>\n",
              "      <td>0.007358</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce96f3b3-6efa-4cb9-95e0-8fb24d553969')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce96f3b3-6efa-4cb9-95e0-8fb24d553969 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce96f3b3-6efa-4cb9-95e0-8fb24d553969');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     he  Probability\n",
              "9  said     0.393450\n",
              "8  says     0.334239\n",
              "7    is     0.042016\n",
              "6   has     0.019870\n",
              "5   was     0.014306\n",
              "4  will     0.012981\n",
              "3     s     0.012233\n",
              "2   had     0.008396\n",
              "1   and     0.007996\n",
              "0  also     0.007358"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "following_bi('he', bi_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "following_bi('good', bi_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "PYaMwZE9yuH4",
        "outputId": "5e250bfe-633b-45c6-cb14-81a462e1c94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-229f26b2-dd81-4cee-bc53-9dbdd794d421\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>good</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>news</td>\n",
              "      <td>0.097393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>for</td>\n",
              "      <td>0.032351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>at</td>\n",
              "      <td>0.027960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>to</td>\n",
              "      <td>0.027091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>and</td>\n",
              "      <td>0.024719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>as</td>\n",
              "      <td>0.017084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>prices</td>\n",
              "      <td>0.015524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>enough</td>\n",
              "      <td>0.015372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thing</td>\n",
              "      <td>0.015266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>on</td>\n",
              "      <td>0.013823</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-229f26b2-dd81-4cee-bc53-9dbdd794d421')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-229f26b2-dd81-4cee-bc53-9dbdd794d421 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-229f26b2-dd81-4cee-bc53-9dbdd794d421');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     good  Probability\n",
              "9    news     0.097393\n",
              "8     for     0.032351\n",
              "7      at     0.027960\n",
              "6      to     0.027091\n",
              "5     and     0.024719\n",
              "4      as     0.017084\n",
              "3  prices     0.015524\n",
              "2  enough     0.015372\n",
              "1   thing     0.015266\n",
              "0      on     0.013823"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "following_bi('make', bi_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "qImWIWZ-yt8g",
        "outputId": "96110b09-d195-44a8-bdd8-f4c2fd558c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-78fbde06-d28d-46d6-a0a9-c4e327a7ad5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>make</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>a</td>\n",
              "      <td>0.126875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>the</td>\n",
              "      <td>0.121068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>it</td>\n",
              "      <td>0.114708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sure</td>\n",
              "      <td>0.077510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>up</td>\n",
              "      <td>0.046265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>them</td>\n",
              "      <td>0.030279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sense</td>\n",
              "      <td>0.016443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>any</td>\n",
              "      <td>0.014325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>an</td>\n",
              "      <td>0.012470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>people</td>\n",
              "      <td>0.012261</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78fbde06-d28d-46d6-a0a9-c4e327a7ad5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78fbde06-d28d-46d6-a0a9-c4e327a7ad5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78fbde06-d28d-46d6-a0a9-c4e327a7ad5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     make  Probability\n",
              "9       a     0.126875\n",
              "8     the     0.121068\n",
              "7      it     0.114708\n",
              "6    sure     0.077510\n",
              "5      up     0.046265\n",
              "4    them     0.030279\n",
              "3   sense     0.016443\n",
              "2     any     0.014325\n",
              "1      an     0.012470\n",
              "0  people     0.012261"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvJmlGTHkFQe"
      },
      "source": [
        "### Beam Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQoC-YchkFQe"
      },
      "outputs": [],
      "source": [
        "import difflib\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKHWikxKkFQf",
        "outputId": "a1f592e8-1f3a-48e6-e74b-48f092c5d677",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5542"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(b_model.unigram_voc_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GTU1dHEkFQf"
      },
      "outputs": [],
      "source": [
        "#this method calculates distances between words, sort them and returns the N closest ones\n",
        "def close_words(sentence): \n",
        "  choose = len(bi_model.unigram_voc_)#hyper parameter\n",
        "  close = [['*start*']*choose]\n",
        "  \n",
        "  voc = list(bi_model.unigram_voc_.keys())\n",
        "  voc.remove('*UNK*')\n",
        "  voc.remove('*start*')\n",
        "  voc.remove('*end*')\n",
        "\n",
        "  for s in sentence[1:-1]:  \n",
        "    dis = []\n",
        "    for i in voc:\n",
        "\n",
        "      #dis.append((i,1/(editdistance.eval(i, s)+1))) #Levensein distance\n",
        "      dis.append((i,difflib.SequenceMatcher(None, i, s).ratio())) #gestalt pattern matching\n",
        "    dis.sort(key=lambda x: x[1],reverse = True) #sort based on distance\n",
        "    close.append(dis[:choose])\n",
        "  close.append(['*end*']*choose)\n",
        "\n",
        "  return close\n",
        "\n",
        "#this method set a score a sequence according to the formula given\n",
        "def prob_calc(sent,true):\n",
        "  sent = sent.split()\n",
        "  l1 = 0.9 #hyper parameter\n",
        "  l2 = 1 - l1 #hyper parameter\n",
        "\n",
        "  S = 0\n",
        "  for i in range(len(sent)) :\n",
        "    #S -= math.log(1/(editdistance.eval(sent[i], true[i])+1),2)  \n",
        "    S -= math.log(difflib.SequenceMatcher(None, sent[i], true[i]).ratio()+0.0001,2)\n",
        "\n",
        "  return l1*S-l2*bi_model.estimate_sent_prob([sent], padding=False)[0] #calculate bigram and spelling probability\n",
        "\n",
        "#this is the beam search algorithm\n",
        "def beam_search(list_sen,close):\n",
        "  if(len(list_sen) == 2):   #if there are only 2 words left in the sequence\n",
        "    calc_prob = []  \n",
        "    print(list_sen)\n",
        "    for j in close[len(list_sen)-1]: #find the closest words              \n",
        "      calc_prob.append((list_sen[0],j[0],prob_calc(list_sen[0]+' '+j[0],list_sen)))\n",
        "    print('fin')\n",
        "    calc_prob.sort(key=lambda x: x[2])   #sort according to score\n",
        "    #print(calc_prob) \n",
        "\n",
        "  else :  #if there are mroe than two words in the sequence\n",
        "    calc_prob = []  \n",
        "    print(list_sen)\n",
        "    prev = beam_search(list_sen[0:-1],close) #call itslef until there are only two words\n",
        "    for p in prev :  #from the result of the previous score    \n",
        "      for j in close[len(list_sen)-1]:  #for every new word            \n",
        "        calc_prob.append((p,j[0],prob_calc(p+' '+j[0],list_sen)))#calculate probability of the sequence plus the extra word\n",
        "    calc_prob.sort(key=lambda x: x[2])#sort based on socre\n",
        "  print( [calc_prob[0][0]+' '+calc_prob[0][1],calc_prob[1][0]+' '+calc_prob[1][1]])\n",
        "  return  [calc_prob[0][0]+' '+calc_prob[0][1],calc_prob[1][0]+' '+calc_prob[1][1]]#return top two sequnces"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The football test case taken from lecture"
      ],
      "metadata": {
        "id": "e9WAeLfBRMcL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E6VpqIykFQf",
        "outputId": "035c424b-1c27-4c58-9ec1-7c44f75b30e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['*start*', 'he', 'plas', 'god', 'ftbal', '*end*']\n",
            "['*start*', 'he', 'plas', 'god', 'ftbal']\n",
            "['*start*', 'he', 'plas', 'god']\n",
            "['*start*', 'he', 'plas']\n",
            "['*start*', 'he']\n",
            "fin\n",
            "['*start* he', '*start* the']\n",
            "['*start* the past', '*start* the last']\n",
            "['*start* the past good', '*start* the past gold']\n",
            "['*start* the past gold fatal', '*start* the past good fatal']\n",
            "['*start* the past gold fatal *', '*start* the past gold fatal *']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['*start* the past gold fatal *', '*start* the past gold fatal *']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "test = \"*start* he plas god ftbal *end*\".split()\n",
        "beam_search(test,close_words(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create random test cases taken from the test set"
      ],
      "metadata": {
        "id": "8p430q8yRScS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO3gwuGgkFQf"
      },
      "outputs": [],
      "source": [
        "import random \n",
        "\n",
        "false_sents = []  # Randomly remove a letter from each token\n",
        "for sent in test_set:\n",
        "    clean = LM.word_cleaner(sent)\n",
        "    false = []\n",
        "    for token in clean:\n",
        "        if len(token) > 1:\n",
        "            remove_ind = random.randint(0, len(token)-1)\n",
        "            false.append(token[:remove_ind] + token[remove_ind+1:])\n",
        "        else:\n",
        "            false.append(token)\n",
        "    false_sents.append(false)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a test case encountered during testing "
      ],
      "metadata": {
        "id": "ZpoJxILbRXFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = ['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'ther', 'mammal', 'tt', 's', 'vry', 'imple', 'end*']"
      ],
      "metadata": {
        "id": "lw-IefuHly3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beam_search(test,close_words(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqNmiwg6l7Qn",
        "outputId": "a1c772c5-b5ea-451b-f7ff-02e80ae71b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'ther', 'mammal', 'tt', 's', 'vry', 'imple', 'end*']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'ther', 'mammal', 'tt', 's', 'vry', 'imple']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'ther', 'mammal', 'tt', 's', 'vry']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'ther', 'mammal', 'tt', 's']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'ther', 'mammal', 'tt']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'ther', 'mammal']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'ther']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod']\n",
            "['*start*', 'w', 'cn', 'appl', 'his']\n",
            "['*start*', 'w', 'cn', 'appl']\n",
            "['*start*', 'w', 'cn']\n",
            "['*start*', 'w']\n",
            "fin\n",
            "['*start* we', '*start* wa']\n",
            "['*start* we can', '*start* we cent']\n",
            "['*start* we can apply', '*start* we can apple']\n",
            "['*start* we can apply his', '*start* we can apply this']\n",
            "['*start* we can apply this method', '*start* we can apply his method']\n",
            "['*start* we can apply this method to', '*start* we can apply his method to']\n",
            "['*start* we can apply this method to many', '*start* we can apply this method to pay']\n",
            "['*start* we can apply this method to many other', '*start* we can apply this method to pay the']\n",
            "['*start* we can apply this method to many other mammals', '*start* we can apply this method to many other mammal']\n",
            "['*start* we can apply this method to many other mammals that', '*start* we can apply this method to many other mammal that']\n",
            "['*start* we can apply this method to many other mammals that is', '*start* we can apply this method to many other mammal that is']\n",
            "['*start* we can apply this method to many other mammals that is very', '*start* we can apply this method to many other mammal that is very']\n",
            "['*start* we can apply this method to many other mammals that is very simple', '*start* we can apply this method to many other mammal that is very simple']\n",
            "['*start* we can apply this method to many other mammals that is very simple *', '*start* we can apply this method to many other mammals that is very simple *']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['*start* we can apply this method to many other mammals that is very simple *',\n",
              " '*start* we can apply this method to many other mammals that is very simple *']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the same case after changing one word. Notice the difference in the plurality of mammals due to the change."
      ],
      "metadata": {
        "id": "wh1uuz_VRpok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = ['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'a', 'mammal', 'tt', 's', 'vry', 'imple', 'end*']\n",
        "beam_search(test,close_words(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8-yqEFhpMeQ",
        "outputId": "19deaecd-ba28-4886-db30-92caee0191d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'a', 'mammal', 'tt', 's', 'vry', 'imple', 'end*']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'a', 'mammal', 'tt', 's', 'vry', 'imple']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'a', 'mammal', 'tt', 's', 'vry']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'a', 'mammal', 'tt', 's']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'a', 'mammal', 'tt']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'a', 'mammal']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may', 'a']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't', 'may']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod', 't']\n",
            "['*start*', 'w', 'cn', 'appl', 'his', 'metod']\n",
            "['*start*', 'w', 'cn', 'appl', 'his']\n",
            "['*start*', 'w', 'cn', 'appl']\n",
            "['*start*', 'w', 'cn']\n",
            "['*start*', 'w']\n",
            "fin\n",
            "['*start* we', '*start* wa']\n",
            "['*start* we can', '*start* we cent']\n",
            "['*start* we can apply', '*start* we can apple']\n",
            "['*start* we can apply his', '*start* we can apply this']\n",
            "['*start* we can apply this method', '*start* we can apply his method']\n",
            "['*start* we can apply this method to', '*start* we can apply his method to']\n",
            "['*start* we can apply this method to many', '*start* we can apply this method to pay']\n",
            "['*start* we can apply this method to pay a', '*start* we can apply this method to many a']\n",
            "['*start* we can apply this method to pay a mammal', '*start* we can apply this method to pay a mammals']\n",
            "['*start* we can apply this method to pay a mammal that', '*start* we can apply this method to pay a mammal test']\n",
            "['*start* we can apply this method to pay a mammal that is', '*start* we can apply this method to pay a mammal that as']\n",
            "['*start* we can apply this method to pay a mammal that is very', '*start* we can apply this method to pay a mammal that as very']\n",
            "['*start* we can apply this method to pay a mammal that is very simple', '*start* we can apply this method to pay a mammal that is very simply']\n",
            "['*start* we can apply this method to pay a mammal that is very simple *', '*start* we can apply this method to pay a mammal that is very simple *']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['*start* we can apply this method to pay a mammal that is very simple *',\n",
              " '*start* we can apply this method to pay a mammal that is very simple *']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This picks a random test case"
      ],
      "metadata": {
        "id": "e6QbiFZyR2Di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ind = random.randint(0, len(false_sents))\n",
        "test = ['*start*', *false_sents[ind], '*end*']\n",
        "beam_search(test,close_words(test))\n",
        "print(f'Correct Sentence: {LM.word_cleaner(test_set[ind])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hflkXHqywgUV",
        "outputId": "a5e145d7-3dce-46c3-a581-d49c89fabd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['*start*', 'toay', 'th', 'mazon', 'lows', 'ino', 'te', 'atlatic', 'ocan', '*end*']\n",
            "['*start*', 'toay', 'th', 'mazon', 'lows', 'ino', 'te', 'atlatic', 'ocan']\n",
            "['*start*', 'toay', 'th', 'mazon', 'lows', 'ino', 'te', 'atlatic']\n",
            "['*start*', 'toay', 'th', 'mazon', 'lows', 'ino', 'te']\n",
            "['*start*', 'toay', 'th', 'mazon', 'lows', 'ino']\n",
            "['*start*', 'toay', 'th', 'mazon', 'lows']\n",
            "['*start*', 'toay', 'th', 'mazon']\n",
            "['*start*', 'toay', 'th']\n",
            "['*start*', 'toay']\n",
            "fin\n",
            "['*start* today', '*start* to']\n",
            "['*start* to the', '*start* today the']\n",
            "['*start* to the main', '*start* to the moon']\n",
            "['*start* to the main flows', '*start* to the moon flows']\n",
            "['*start* to the main flows in', '*start* to the moon flows in']\n",
            "['*start* to the main flows in the', '*start* to the moon flows in the']\n",
            "['*start* to the main flows in the atlantic', '*start* to the moon flows in the atlantic']\n",
            "['*start* to the main flows in the atlantic ocean', '*start* to the moon flows in the atlantic ocean']\n",
            "['*start* to the main flows in the atlantic ocean *', '*start* to the main flows in the atlantic ocean *']\n",
            "Correct Sentence: ['today', 'the', 'amazon', 'flows', 'into', 'the', 'atlantic', 'ocean']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d730a2b9894ef36cca77d717dfbf37657b5f05c487fae01f16d101a9a41534c0"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Assignment_1_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}